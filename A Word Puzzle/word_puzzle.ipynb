{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c03d3fd2-a1c6-4257-aed4-dd50f7ea3a45",
   "metadata": {},
   "source": [
    "<h1>What does this program do?</h1>\n",
    "\n",
    "Turn a selection of words into a puzzle.\n",
    "\n",
    "<h2>What is the puzzle?</h2>\n",
    "\n",
    "One aspect of every word changes, and the reader must either figure out what changed, or what the original text said.\n",
    "\n",
    "<h2>What is changed about the words?</h2>\n",
    "\n",
    "There are three possible changes for each word: spelling, pronounciation, and definition.\n",
    "\n",
    "<h3>Definition</h3>\n",
    "\n",
    "The program looks the word up in an online dictionary, and replaces it with a word offset from the original by some amount. For example, the 10th word after it, or the 6th word before it.\n",
    "\n",
    "<h3>Spelling & Pronounciation</h3>\n",
    "\n",
    "Since this puzzle is entirely text-based, changes to pronounciation must actually affect its spelling. Therefore, changes to spelling and pronounciation both change spelling, but in different ways.\n",
    "\n",
    "A word consists of three aspects: appearance, sound, and meaning. Its meaning is abstract, applied to a word by historical use and present societal use and understanding. As for appearance and sound, a graphical representation of an English word consists of letters, which then represent sounds. Individual sounds are called __phonemes__, and the letters or groups of letters that represent phonemes are called __graphemes__.\n",
    "\n",
    "Phonemes in English have a plethora of irregular spellings, some only appearing in a single word (and its derivatives). That is what my program will play on. When changing the _spelling_ of a word, it will pick a random phoneme and its associated grapheme in the word, and change the grapheme to another valid representation of that same phoneme, for example changing 'thaw' to 'tho', where the 'aw' sound is spelled like the 'o' in 'bog'. However, when changing a _pronounciation_, it selects a random phoneme in the word and replaces it with another phoneme, and pick a valid grapheme.\n",
    "\n",
    "<h4>How does the program know what phonemes are?</h4>\n",
    "It will look up the word on Wiktionary, which has the IPA representation of the word. Each IPA symbol is a phoneme, and each phoneme is exactly one symbol.\n",
    "\n",
    "<h4>How will Python recognize IPA symbols?</h4>\n",
    "Hopefully I can use Unicode. Otherwise, I don't know\n",
    "\n",
    "<h4>What about English vowels? How will you represent their complexity?</h4>\n",
    "\n",
    "\n",
    "<h1>IDEA:</h1>\n",
    "instead of directly changing the phoneme/grapheme, the program picks an English dialect to start with, and another to change it to. It then changes the spelling of the word to match how someone speaking the first dialect would spell the pronounciation of someone in the second dialect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1984a3c2-5a85-4ee2-9a81-f3817a2de78c",
   "metadata": {},
   "source": [
    "10/15\n",
    "\n",
    "Step 1: write code that can understand phonemes and break words down into them\n",
    "\n",
    "Step 2: use some base text to derive all possible spellings of each phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a977bc28-4a0f-4c5c-a610-5183d58fee54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will \n"
     ]
    }
   ],
   "source": [
    "with open('dracula_frankenstein.txt', 'r', encoding='utf-8') as f:\n",
    "    rawText = f.read()\n",
    "\n",
    "print(rawText[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4709e57-9116-4b36-bdca-5a9678a21341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!EXCLAMATION-POINT  EH2 K S K L AH0 M EY1 SH AH0 N P OY2 N T\n"
     ]
    }
   ],
   "source": [
    "with open('cmuDict.txt', 'r', encoding='utf-8') as f:\n",
    "    rawDict = f.read()\n",
    "\n",
    "cmu = rawDict.split('\\n')[56:]\n",
    "print(cmu[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb025922-bd4d-487e-ad2d-aac5f73e3b78",
   "metadata": {},
   "source": [
    "Problem: though I now have a phonetic spelling of most English words, it cannot tell me which grapheme each sound belongs to. Some graphemes consist of multiple letters, and others represent multiple distinct phonemes\n",
    "\n",
    "Solution?: first, assume that each letter is its own grapheme. if correct, then move on. otherwise, for the graphemes that do not cleanly match, try sticking letters together until it matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d394ace-e177-4af0-9922-8905c8eea77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXCLAMATION-POINT \n",
      " EH2 K S K L AH0 M EY1 SH AH0 N P OY2 N T\n"
     ]
    }
   ],
   "source": [
    "testWord = cmu[0].strip('! ')\n",
    "word, pron = testWord.split(maxsplit=1)\n",
    "word = word.strip()\n",
    "pron = pron.strip()\n",
    "print(word, '\\n', pron)\n",
    "phonemes_old = pron.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37feb175-84d1-48d3-97d0-7d16bdc7f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "class coolWord:\n",
    "    def __init__(self, spelling):\n",
    "        self.s = spelling\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05033e3b-6396-4f90-82f0-3166fe89d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseWords = rawText.split()\n",
    "baseWords = set(baseWords)\n",
    "for word in baseWords:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016d7a94-40ff-4305-a007-2287be0b8333",
   "metadata": {},
   "source": [
    "10/17\n",
    "\n",
    "in the ARPAbet, some symbols represent vowel sounds, and others consonants. there is always at least one vowel per word. so, words can be broken up into chunks with exactly one vowel sound each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04dee34e-c1df-4d46-a6df-aa40e97954e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_words = {}\n",
    "for w in cmu:\n",
    "    try:\n",
    "        t, p = w.split(maxsplit=1)\n",
    "        useful_words[t] = p\n",
    "    except (IndexError, ValueError) as e:\n",
    "        print(w)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b41381-5fe8-4852-a672-21df1ba1dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_words = {w.split(maxsplit=1)[0]: w.split(maxsplit=1)[1] for w in cmu}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13c0d717-2009-4e9b-ba7c-c20e336ac645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L IY0 EY1 Z AA2 N'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_words['LIAISON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b35962-1d72-4c1b-afdb-c234756fd459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONSON(1) \n",
      " AA1 R AH0 N S AH0 N\n"
     ]
    }
   ],
   "source": [
    "testWord2 = cmu[100].strip('! ')\n",
    "word, pron = testWord2.split(maxsplit=1)\n",
    "word = word.strip()\n",
    "pron = pron.strip()\n",
    "print(word, '\\n', pron)\n",
    "phonemes = pron.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77a2eb31-baa3-4dbc-a865-280951b9ce96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(phonemes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63e557c3-a9ce-4e2c-9b32-8d900697587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = [    # General American English specifically\n",
    "    'AA',     # balm, bot\n",
    "    'AE',     # bat\n",
    "    'AH',     # butt\n",
    "    'AO',     # stOry      this gave me a heart attack when Wikipedia gave another example as 'cAUGHt' which is not at all the same sound to me\n",
    "    'AW',     # bout\n",
    "    'AX',     # commA (schwa)\n",
    "    'AY',     # bite\n",
    "    'EH',     # bet\n",
    "    'ER',     # bIRd, forewORd\n",
    "    'EY',     # bait\n",
    "    'IH',     # bit\n",
    "    'IX',     # rosEs, rabbIt\n",
    "    'IY',     # beat\n",
    "    'OW',     # boat\n",
    "    'OY',     # boy\n",
    "    'UH',     # book\n",
    "    'UW'      # boot\n",
    "]\n",
    "# source: https://en.wikipedia.org/wiki/ARPABET\n",
    "consonants = [\n",
    "    'B',      # buy\n",
    "    'CH',     # China\n",
    "    'D',      # die\n",
    "    'DH',     # thy\n",
    "    'DX',     # buTTer\n",
    "    'EL',     # bottLE\n",
    "    'EM',     # rhythM\n",
    "    'EN',     # buttON\n",
    "    'F',      # fight\n",
    "    'G',      # guy\n",
    "    'HH',     # High\n",
    "    'JH',     # jive\n",
    "    'K',      # kite\n",
    "    'L',      # lie\n",
    "    'M',      # my\n",
    "    'N',      # nigh\n",
    "    'NG',     # siNG\n",
    "    'P',      # pie\n",
    "    'Q',      # uh-oh (glottal stop)\n",
    "    'R',      # rye\n",
    "    'S',      # sigh\n",
    "    'SH',     # shy\n",
    "    'T',      # tie\n",
    "    'TH',     # thigh\n",
    "    'V',      # vie\n",
    "    'W',      # wise\n",
    "    'WH',     # why (for fancy people)\n",
    "    'Y',      # yacht\n",
    "    'Z',      # zoo\n",
    "    'ZH'      # pleaSure\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e299868-317e-48a6-b94e-ada85542643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class coolWord:\n",
    "    def __init__(self, spelling, pronounciation):\n",
    "        symbols = \"~!@#$%^&*()-_=+[]{}\\\\|;:\\'\\\",<.>/?1234567890\"\n",
    "        self.word = spelling.strip(symbols).lower()\n",
    "        ps = pronounciation.split()\n",
    "        ps2 = [p.strip(symbols) for p in ps]\n",
    "        self.p = ' '.join(ps2)        \n",
    "        self.x = False\n",
    "        self.xx = False\n",
    "        self.xIndex = 0\n",
    "        if 'x' in self.word:\n",
    "            self.x = True\n",
    "            if 'xx' in self.word:\n",
    "                self.xx = True\n",
    "                self.s = self.word.replace('xx', 'ks')\n",
    "            else:\n",
    "                self.xIndex = self.word.index('x')\n",
    "                if self.xIndex == 0:\n",
    "                    self.s = self.word.replace('x', 'z')\n",
    "                elif self.xIndex == len(self.word) - 1 and ps2[-1] == 'OW':\n",
    "                    self.s = self.word.replace('x', '')\n",
    "                elif self.word[self.xIndex - 1] in 'aeiou' and self.xIndex != len(self.word) - 1 and self.word[self.xIndex + 1] in 'aeiou':\n",
    "                    self.s = self.word.replace('x', 'gz')\n",
    "                else:\n",
    "                    self.s = self.word.replace('x', 'ks')\n",
    "        else:\n",
    "            self.s = self.word\n",
    "    def __str__(self):\n",
    "        return self.word\n",
    "    def __repr__(self):\n",
    "        return self.word\n",
    "    def atomize(self, v, c):\n",
    "        current_letters = []\n",
    "        current_sounds = []\n",
    "        final = {}\n",
    "        vows = []\n",
    "        cons = []\n",
    "        letter_counter = 0\n",
    "        while letter_counter < len(self.s):\n",
    "            current_letter = letter_counter\n",
    "            while letter_counter < len(self.s) and self.s[letter_counter] in \"qwrtypsdfghjklzxcvbnm\":\n",
    "                current_letters.append(self.s[letter_counter])\n",
    "                letter_counter += 1\n",
    "            final[current_letter] = ''.join(current_letters)\n",
    "            current_letters = []\n",
    "            if letter_counter >= len(self.s):\n",
    "                break\n",
    "            current_letter = letter_counter\n",
    "            while letter_counter < len(self.s) and self.s[letter_counter] in \"aeiou\":\n",
    "                current_letters.append(self.s[letter_counter])\n",
    "                letter_counter += 1\n",
    "            final[current_letter] = ''.join(current_letters)\n",
    "            current_letters = []\n",
    "        self.c = cons\n",
    "        self.v = vows\n",
    "        self.f = final\n",
    "#        for i in self.p:\n",
    "#            if i in v:\n",
    "#                pass\n",
    "#            elif i in c:\n",
    "#                current_sounds.append(i)\n",
    "#                self.c[letter_counter].append(current_letters)\n",
    "#                letter_counter += 1\n",
    "#            else:\n",
    "#                print(\"weirdo ->\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c21471a5-4562-4a9c-83e1-6349eeedd351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AA1 NG K S T'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_words['ANGST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "815f4ade-b093-4081-ab52-73632fabe759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TH AO1 T'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_words['THOUGHT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84d3a619-d778-46c9-b088-caf40e5ddc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordObjs = []\n",
    "for line in cmu:\n",
    "    wordObjs.append(coolWord(*line.split(maxsplit=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c12f3118-d319-4fd1-a4e8-b0ba9418b8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclamation-point\n"
     ]
    }
   ],
   "source": [
    "print(wordObjs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14ca3ac9-f588-4b68-b0dc-62ebd958a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordObjs2 = {line.split(maxsplit=1)[0]: coolWord(*line.split(maxsplit=1)) for line in cmu}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0314b3d4-98ba-4822-a07d-9548f87c1ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'h', 1: 'e', 2: 'll', 4: 'o'}\n",
      "HH AH L OW\n"
     ]
    }
   ],
   "source": [
    "hello = wordObjs2['HELLO']\n",
    "hello.atomize('v', 'c')\n",
    "print(hello.f)\n",
    "print(hello.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a4bca-3748-4167-831d-24d0660e3f2f",
   "metadata": {},
   "source": [
    "10/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dff804e-6eee-45d6-8e2e-1e9856f91313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPhoneStructure(word):\n",
    "    phones = []\n",
    "    for phone in word.p.split():\n",
    "        if phone in vowels:\n",
    "            phones.append('V')\n",
    "        else:\n",
    "            phones.append('C')\n",
    "    return ''.join(phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "667092dc-c806-4338-9a26-eb60ce5e346a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CVCV'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPhoneStructure(wordObjs2['HELLO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e69ebef-2f00-44b1-a5aa-53beb0119289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'a', 1: 'ngst'}\n",
      "AA NG K S T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'VCCCC'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angst = wordObjs2['ANGST']\n",
    "angst.atomize('v', 'c')\n",
    "print(angst.f)\n",
    "print(angst.p)\n",
    "getPhoneStructure(angst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01fefa7c-aa32-4e40-a609-63c7d03d535e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B IH N JH'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordObjs2['BINGE'].p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fabe362-d9c3-4a8a-ad90-35b6a68aa937",
   "metadata": {},
   "source": [
    "start at the end of a word.\n",
    "\n",
    "if it ends in a vowel sound, then the last letter must be part of a vowel phoneme.\n",
    "<ul>\n",
    "    <li>if the next sound is also a vowel, find the amount of vowel phonemes at the end (vPhon) and vowel letters (vLet)</li>\n",
    "    <ul>\n",
    "        <li>if those are equal, assign each phoneme to each letter in order as its grapheme. [note: is this always accurate?]</li>\n",
    "        <li>then return to loop</li>\n",
    "        <li>otherwise, ???</li>\n",
    "    </ul>\n",
    "    <li>otherwise, while the last letter is not a vowel, add letters to the current grapheme.</li>\n",
    "    <ul>\n",
    "        <li>once the last letter is a vowel(aeiouy), add that to the grapheme.</li>\n",
    "        <li>If the next letter is a vowel and the next sound is not, add vowels until you reach a consonant</li>\n",
    "        <li>Otherwise, return to start of loop</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "if the word ends in a consonant sound, then the last letter must be part of a consonant phoneme.\n",
    "<ul>\n",
    "    <li>add all letters to the current grapheme, until reaching a vowel letter, unless the first letter is a vowel</li>\n",
    "    <li>add all consonant phonemes up to the next vowel sound to some object, to analyze later. do the same for the letters</li>\n",
    "    \n",
    "</ul>\n",
    "then, sort out any clumps of consonants (somehow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c2edf0e-ce73-49a7-81e0-4733cfa8fd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'th', 2: 'ou', 4: 'ght'}\n",
      "TH AO T\n"
     ]
    }
   ],
   "source": [
    "thought = wordObjs2['THOUGHT']\n",
    "thought.atomize('v', 'c')\n",
    "print(thought.f)\n",
    "print(thought.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d931252c-c882-440e-a0f3-628e3da8e65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'v', 1: 'i', 2: 'll', 4: 'a'}\n",
      "V IH L AH\n"
     ]
    }
   ],
   "source": [
    "villa = wordObjs2['VILLA']\n",
    "villa.atomize('v', 'c')\n",
    "print(villa.f)\n",
    "print(villa.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf9012c6-ac09-421c-be1c-0868b1f3265a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'sh', 2: 'i', 3: 'ngl', 6: 'e'}\n",
      "SH IH NG G AH L\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CVCCVC'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shingle = wordObjs2['SHINGLE']\n",
    "shingle.atomize('v', 'c')\n",
    "print(shingle.f)\n",
    "print(shingle.p)\n",
    "getPhoneStructure(shingle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d9d0132-9436-46fc-ad67-d46fdae3d918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'm', 1: 'i', 2: 'ssh', 5: 'a', 6: 'p', 7: 'e', 8: 'n'}\n",
      "M IH S SH EY P AH N\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CVCCVCVC'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misshapen = wordObjs2['MISSHAPEN']\n",
    "misshapen.atomize('v', 'c')\n",
    "print(misshapen.f)\n",
    "print(misshapen.p)\n",
    "getPhoneStructure(misshapen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbe2816f-a65e-4ca7-8c14-602a592f16fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'm', 1: 'i', 2: 'ss', 4: 'i', 5: 'l', 6: 'e'}\n",
      "M IH S AH L\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CVCVC'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missile = wordObjs2['MISSILE']\n",
    "missile.atomize('v', 'c')\n",
    "print(missile.f)\n",
    "print(missile.p)\n",
    "getPhoneStructure(missile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1f14e-7dbd-46c3-aa06-1b5d216b8910",
   "metadata": {},
   "source": [
    "the first letter of a word must belong to its first phoneme, and the last letter must belong to its last phoneme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f9ba2-7213-45ff-a896-6edf3eb7292b",
   "metadata": {},
   "source": [
    "what if you gave a program the very basic pronounciations of letters, and when it comes across a word that it cannot pronounce, have it learn the new pronounciations?\n",
    "\n",
    "or, give it the basic spellings of phonemes, and when it doesn't spell a word right, have it learn the spelling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0470fa6-b077-451e-9327-caff1b42894c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 's', 1: 'i', 2: 'ng', 4: 'e', 5: 'r'}\n",
      "S IH NG ER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CVCV'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singer = wordObjs2['SINGER']\n",
    "singer.atomize('v', 'c')\n",
    "print(singer.f)\n",
    "print(singer.p)\n",
    "getPhoneStructure(singer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7739c51-e216-41dc-8b48-8c097b890557",
   "metadata": {},
   "outputs": [],
   "source": [
    "spellings = {\n",
    "    'AA': ['o'],\n",
    "    'AE': ['a'],\n",
    "    'AH': ['u'],\n",
    "    'AO': ['o'],\n",
    "    'AW': ['ou'],\n",
    "    'AX': ['a'],\n",
    "    'AXR': ['er'],\n",
    "    'AY': ['i'],\n",
    "    'EH': ['e'],\n",
    "    'ER': ['ir'],\n",
    "    'EY': ['ai'],\n",
    "    'IH': ['i'],\n",
    "    'IX': ['e'],\n",
    "    'IY': ['ea'],\n",
    "    'OW': ['oa'],\n",
    "    'OY': ['oy'],\n",
    "    'UH': ['oo'],\n",
    "    'UW': ['oo'],\n",
    "    'UX': ['u'],\n",
    "    'B': ['b'],\n",
    "    'CH': ['ch'],\n",
    "    'D': ['d'],\n",
    "    'DX': ['tt'],\n",
    "    'EL': ['le'],\n",
    "    'EM': ['m'],\n",
    "    'EN': ['on'],\n",
    "    'F': ['f'],\n",
    "    'G': ['g'],\n",
    "    'H': ['h'],\n",
    "    'HH': ['h'],\n",
    "    'JH': ['j'],\n",
    "    'K': ['k'],\n",
    "    'L': ['l'],\n",
    "    'M': ['m'],\n",
    "    'N': ['n'],\n",
    "    'NX': ['ng'],\n",
    "    'NG': ['ng'],\n",
    "    'P': ['p'],\n",
    "    'Q': ['-'],\n",
    "    'R': ['r'],\n",
    "    'S': ['s'],\n",
    "    'SH': ['sh'],\n",
    "    'T': ['t'],\n",
    "    'TH': ['th'],\n",
    "    'V': ['v'],\n",
    "    'W': ['w'],\n",
    "    'WH': ['wh'],\n",
    "    'Y': ['y'],\n",
    "    'Z': ['z'],\n",
    "    'ZH': ['s']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "855eac42-fd50-42e3-bd50-9741ef66507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell(word):\n",
    "    phones = word.p.split()\n",
    "    spelling = []\n",
    "    for p in phones:\n",
    "        spelling.append(spellings[p][0])\n",
    "    return spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f85e1123-0479-40d6-826a-69ca73baaa2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'u', 'l', 'oa']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell(wordObjs2['HELLO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb9943c5-639a-4f70-8b89-000f6d0f796e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'a', 't']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell(wordObjs2['BAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e0e41da-cbde-44a7-823b-4fc4ee0c9704",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordObjs2 = {word: wordObjs2[word] for word in wordObjs2 if len(wordObjs2[word].p.split()) < 2 * len(word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95898a53-8be1-4f2c-83de-00bb41d02ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "threeLetter = [wordObjs2[word] for word in wordObjs2 if len(wordObjs2[word].s) == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dca8342-e899-4f22-a67a-948205e0498b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1662"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(threeLetter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff0e21ec-0599-4b38-bbad-55fda6b4534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "twoLetter = [wordObjs2[word] for word in wordObjs2 if len(wordObjs2[word].s) == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cff30ca2-f46b-47e7-9481-ca21bd31e508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twoLetter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd562875-52c2-4692-a677-79815a1e9356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em: AH M: ['u', 'm']\n"
     ]
    }
   ],
   "source": [
    "for word in twoLetter:\n",
    "    news = spell(word)\n",
    "    print(f\"{word.s.lower()}: {word.p}: {news}\")\n",
    "    if word.s.lower() != news:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3069a91-4b93-4463-9be7-cb727b855174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'i']\n"
     ]
    }
   ],
   "source": [
    "print(spell(wordObjs2['BY']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "515bfd8e-2ad1-4f3a-8a06-f5b788b1bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell2(word):\n",
    "    phones = word.p.split()\n",
    "    spelling = []\n",
    "    \n",
    "    while ''.join(spelling) != word.s:\n",
    "        spelling = []\n",
    "        for p in phones:\n",
    "            pass\n",
    "            #if ''.join(spelling + spellings[p][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "818786ca-a610-4f0a-8a4e-0cc24b9493c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(''.join([])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aae17c-b174-4c44-aa32-c6b394e439d1",
   "metadata": {},
   "source": [
    "10/24\n",
    "\n",
    "So I have the basic framework: the program \"learns\" every possible different spelling of each English phoneme, by trying to spell words and memorizing new spellings.\n",
    "However, this assumes that each word has one new grapheme maximum. Any more and it couldn't tell them apart.\n",
    "\n",
    "So, it must start with small words, to minimize the chance of multiple new graphemes per word. It'll start with two-letter words, then three, and so on.\n",
    "\n",
    "However. It still needs a way to figure out which part is misspelled, and there's not a simple way to subtract two arbitrary strings. They could be different lengths, offsetting the letters from each other, so a 1-1 comparison wouldn't work.\n",
    "\n",
    "But I had an idea in the shower yesterday: we're already assuming that there's no more than one new grapheme per word, and we can use that here.\n",
    "\n",
    "We have the original word, with its pronounciation, as well as the code's attempt at spelling it. The attempt is also split into its graphemes.\n",
    "\n",
    "1. Start at the beginning of the original word. Check if it starts with the same letters as the first guessed grapheme.\n",
    "2. If it does, then we discard those letters, and repeat with the next grapheme.\n",
    "3. If not, then we learn that new grapheme.\n",
    "\n",
    "However, this method has a critical flaw.\n",
    "\n",
    "A word starting with the same letters as the guessed grapheme does not mean that it guessed the grapheme correctly. For example, say the original word is 'witty' and it guessed 'wity'. It would recognize that it spelled 'w' and 'i' correctly, so it looks at the rest of the word, 'tty'. 'tty' starts with 't', so it would recognize that as correct, and remove one 't'. Then, it checks the remaining 'ty', and finds that its guess of 'y' was incorrect, learning 'ty' as a new spelling. But this was incorrect.\n",
    "\n",
    "<ul>\n",
    "    <li>Starting at the end of the word instead would not fix the issue.</li>\n",
    "    <li>I did have an idea on Tuesday:</li>\n",
    "</ul>\n",
    "\n",
    "1. Start at index 0 of the original word. Capture letters from the word until it finds a letter that doesn't match the guess.\n",
    "2. Do this for every index (letter)\n",
    "3. Check each group of letters to see if they correspond to a guessed grapheme.\n",
    "\n",
    "I FORGOT MY BETTER IDEA FROM THE SHOWER (included below) (I had the basic idea in the shower, but actually worked it out and refined it today)\n",
    "\n",
    "<ol>\n",
    "    <li>Guess a spelling for the first phoneme.</li>\n",
    "    <li>If the word starts with that spelling, then save that guess.</li>\n",
    "    <li>If it doesn't start with that, guess another spelling until it matches.</li>\n",
    "    <ol>\n",
    "        <li>If no known graphemes match, skip to step 8.</li>\n",
    "    </ol>\n",
    "    <li>Guess a spelling for the second phoneme.</li>\n",
    "    <li>Add it to the current correct guess, and check whether it matches the start of the word.</li>\n",
    "    <li>If it does, save that guess and repeat steps 5-6.</li>\n",
    "    <li>If the current correct guess is the same as the original word, then it is spelled correctly. Exit loop.</li>\n",
    "    <li>Do the same procedure, but starting at the end of the word. Save the current correct guess from this step separately.</li>\n",
    "    <li></li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6dfd671c-13bd-4b2a-a9b8-622d86d8ecfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bordeaux bordeau\n",
      "{0: 'b', 1: 'o', 2: 'rd', 4: 'eau'}\n",
      "B AO R D OW\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CVCCV'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which = wordObjs2['BORDEAUX']\n",
    "print(which.word, which.s)\n",
    "which.atomize('v', 'c')\n",
    "print(which.f)\n",
    "print(which.p)\n",
    "getPhoneStructure(which)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bda8951-4c86-4193-850a-7b00743b584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from copy import copy\n",
    "\n",
    "def sideSpell(word, phones, spellings, polarity):\n",
    "    currentSpell = []\n",
    "    for p in phones:\n",
    "        oldLen = len(currentSpell)\n",
    "        for s in spellings[p]:\n",
    "            newSpell = copy(currentSpell)\n",
    "            if not polarity:\n",
    "                newSpell.append(s)\n",
    "                if word.s.startswith(''.join(newSpell)):\n",
    "                    currentSpell.append(s)\n",
    "                    break\n",
    "            else:\n",
    "                newSpell.insert(0, s)\n",
    "                if word.s.endswith(''.join(newSpell)):\n",
    "                    currentSpell.insert(0, s)\n",
    "                    break                \n",
    "        if len(currentSpell) == oldLen:\n",
    "            break\n",
    "    return currentSpell\n",
    "\n",
    "def spell3(word, spellings):\n",
    "    word.s = word.s.lower()\n",
    "    if not word.s.isalnum():\n",
    "        print(\"bad characters\", word.s)\n",
    "        return False\n",
    "    print(word)\n",
    "    phones = word.p.split()\n",
    "    if len(word.s) < len(phones):\n",
    "        print(\"too long!\", word.s, phones)\n",
    "        return False\n",
    "    if word.s[:-2] == 'le' and phones[:-2] == ['AH', 'L'] and word.s[-3] not in ['aeiou']:\n",
    "        phones.append(phones.pop[-2])\n",
    "        print(\"special case: L\")\n",
    "    rphones = copy(phones)\n",
    "    rphones.reverse()\n",
    "    print(\"phones\", phones, rphones)\n",
    "    frontSpell = sideSpell(word, phones, spellings, 0)\n",
    "    backSpell = sideSpell(word, rphones, spellings, 1)\n",
    "    print(\"front & back\", frontSpell, backSpell)\n",
    "    if '' in frontSpell:\n",
    "        frontSpell.remove('')\n",
    "    if '' in backSpell:\n",
    "        backSpell.remove('')\n",
    "    if frontSpell == backSpell and ''.join(frontSpell) == word.s:\n",
    "        print('yay!')\n",
    "        return True\n",
    "    missingG = word.s.removeprefix(''.join(frontSpell)).removesuffix(''.join(backSpell))\n",
    "    if not missingG:\n",
    "        missingG = backSpell[0]\n",
    "    print(\"missing grapheme\", missingG)\n",
    "    if len(frontSpell + backSpell) > len(phones):\n",
    "            #print(word, frontSpell, len(frontSpell))\n",
    "            #print(backSpell, len(backSpell))\n",
    "            #print(phones)\n",
    "            print(\"too long\")\n",
    "            del backSpell[0]\n",
    "    if len(frontSpell + backSpell) < len(phones):\n",
    "        try:\n",
    "            missingP = phones[len(frontSpell)]\n",
    "            print(\"missing phoneme (clean)\", missingP)\n",
    "            spellings[missingP].append(missingG)\n",
    "        except IndexError as e:\n",
    "            print(word, frontSpell, len(frontSpell))\n",
    "            print(backSpell, len(backSpell))\n",
    "            print(phones)\n",
    "            raise e\n",
    "    else:\n",
    "        missingP = phones[len(frontSpell) - 1]\n",
    "        print(\"missing phoneme (overlap)\", missingP)\n",
    "        try:\n",
    "            spellings[missingP].append(''.join((frontSpell[-1], missingG) if frontSpell else (missingG, backSpell[0])))\n",
    "            print(''.join((frontSpell[-1], missingG) if frontSpell else (missingG, backSpell[0])))\n",
    "        except IndexError as e:\n",
    "            print(word, frontSpell, len(frontSpell))\n",
    "            print(backSpell, len(backSpell))\n",
    "            print(phones)\n",
    "            print(missingP)\n",
    "            raise e\n",
    "\n",
    "def learn(spellings, words):\n",
    "    for word in words:\n",
    "        spell3(word, spellings)\n",
    "        print(word, word.p)\n",
    "        break\n",
    "    return spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e168c9c-cde4-4247-b9e9-21c0554f12b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(aDict):\n",
    "    for key in aDict:\n",
    "        while '' in aDict[key]:\n",
    "            aDict[key].remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4955513a-9f41-425c-8b9a-963faa889a01",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "spellings = {\n",
    "    'AA': ['o'],\n",
    "    'AE': ['a'],\n",
    "    'AH': ['u'],\n",
    "    'AO': ['o'],\n",
    "    'AW': ['ou'],\n",
    "    'AX': ['a'],\n",
    "    'AXR': ['er'],\n",
    "    'AY': ['i'],\n",
    "    'EH': ['e'],\n",
    "    'ER': ['ir'],\n",
    "    'EY': ['ai'],\n",
    "    'IH': ['i'],\n",
    "    'IX': ['e'],\n",
    "    'IY': ['ea'],\n",
    "    'OW': ['oa'],\n",
    "    'OY': ['oy'],\n",
    "    'UH': ['oo'],\n",
    "    'UW': ['oo'],\n",
    "    'UX': ['u'],\n",
    "    'B': ['b'],\n",
    "    'CH': ['ch'],\n",
    "    'D': ['d'],\n",
    "    'DX': ['tt'],\n",
    "    'EL': ['le'],\n",
    "    'EM': ['m'],\n",
    "    'EN': ['on'],\n",
    "    'F': ['f'],\n",
    "    'G': ['g'],\n",
    "    'H': ['h'],\n",
    "    'HH': ['h'],\n",
    "    'JH': ['j'],\n",
    "    'K': ['k'],\n",
    "    'L': ['l'],\n",
    "    'M': ['m'],\n",
    "    'N': ['n'],\n",
    "    'NX': ['ng'],\n",
    "    'NG': ['ng'],\n",
    "    'P': ['p'],\n",
    "    'Q': ['-'],\n",
    "    'R': ['r'],\n",
    "    'S': ['s'],\n",
    "    'SH': ['sh'],\n",
    "    'T': ['t'],\n",
    "    'TH': ['th'],\n",
    "    'V': ['v'],\n",
    "    'W': ['w'],\n",
    "    'WH': ['wh'],\n",
    "    'Y': ['y'],\n",
    "    'Z': ['z'],\n",
    "    'ZH': ['s']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6563e978-892b-4cf3-92d3-7a5045b172b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mo\n",
      "phones ['M', 'OW'] ['OW', 'M']\n",
      "front & back ['m'] []\n",
      "missing grapheme o\n",
      "missing phoneme (clean) OW\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "spell3(choice(twoLetter), spellings)\n",
    "clean(spellings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4742dbfc-fac1-4c60-917b-ee5c6bb4f136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA': ['o'],\n",
       " 'AE': ['a'],\n",
       " 'AH': ['u'],\n",
       " 'AO': ['o'],\n",
       " 'AW': ['ou'],\n",
       " 'AX': ['a'],\n",
       " 'AXR': ['er'],\n",
       " 'AY': ['i'],\n",
       " 'EH': ['e'],\n",
       " 'ER': ['ir'],\n",
       " 'EY': ['ai'],\n",
       " 'IH': ['i'],\n",
       " 'IX': ['e'],\n",
       " 'IY': ['ea'],\n",
       " 'OW': ['oa', 'o'],\n",
       " 'OY': ['oy'],\n",
       " 'UH': ['oo'],\n",
       " 'UW': ['oo'],\n",
       " 'UX': ['u'],\n",
       " 'B': ['b'],\n",
       " 'CH': ['ch'],\n",
       " 'D': ['d'],\n",
       " 'DX': ['tt'],\n",
       " 'EL': ['le'],\n",
       " 'EM': ['m'],\n",
       " 'EN': ['on'],\n",
       " 'F': ['f'],\n",
       " 'G': ['g'],\n",
       " 'H': ['h'],\n",
       " 'HH': ['h'],\n",
       " 'JH': ['j'],\n",
       " 'K': ['k'],\n",
       " 'L': ['l'],\n",
       " 'M': ['m'],\n",
       " 'N': ['n'],\n",
       " 'NX': ['ng'],\n",
       " 'NG': ['ng'],\n",
       " 'P': ['p'],\n",
       " 'Q': ['-'],\n",
       " 'R': ['r'],\n",
       " 'S': ['s'],\n",
       " 'SH': ['sh'],\n",
       " 'T': ['t'],\n",
       " 'TH': ['th'],\n",
       " 'V': ['v'],\n",
       " 'W': ['w'],\n",
       " 'WH': ['wh'],\n",
       " 'Y': ['y'],\n",
       " 'Z': ['z'],\n",
       " 'ZH': ['s']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8df2e07-f1d2-48f7-8bb1-eee72f6db078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em\n",
      "phones ['AH', 'M'] ['M', 'AH']\n",
      "front & back [] ['m']\n",
      "missing grapheme e\n",
      "missing phoneme (clean) AH\n",
      "em AH M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AA': ['o'],\n",
       " 'AE': ['a'],\n",
       " 'AH': ['u', 'e'],\n",
       " 'AO': ['o'],\n",
       " 'AW': ['ou'],\n",
       " 'AX': ['a'],\n",
       " 'AXR': ['er'],\n",
       " 'AY': ['i'],\n",
       " 'EH': ['e'],\n",
       " 'ER': ['ir'],\n",
       " 'EY': ['ai'],\n",
       " 'IH': ['i'],\n",
       " 'IX': ['e'],\n",
       " 'IY': ['ea'],\n",
       " 'OW': ['oa', 'o'],\n",
       " 'OY': ['oy'],\n",
       " 'UH': ['oo'],\n",
       " 'UW': ['oo'],\n",
       " 'UX': ['u'],\n",
       " 'B': ['b'],\n",
       " 'CH': ['ch'],\n",
       " 'D': ['d'],\n",
       " 'DX': ['tt'],\n",
       " 'EL': ['le'],\n",
       " 'EM': ['m'],\n",
       " 'EN': ['on'],\n",
       " 'F': ['f'],\n",
       " 'G': ['g'],\n",
       " 'H': ['h'],\n",
       " 'HH': ['h'],\n",
       " 'JH': ['j'],\n",
       " 'K': ['k'],\n",
       " 'L': ['l'],\n",
       " 'M': ['m'],\n",
       " 'N': ['n'],\n",
       " 'NX': ['ng'],\n",
       " 'NG': ['ng'],\n",
       " 'P': ['p'],\n",
       " 'Q': ['-'],\n",
       " 'R': ['r'],\n",
       " 'S': ['s'],\n",
       " 'SH': ['sh'],\n",
       " 'T': ['t'],\n",
       " 'TH': ['th'],\n",
       " 'V': ['v'],\n",
       " 'W': ['w'],\n",
       " 'WH': ['wh'],\n",
       " 'Y': ['y'],\n",
       " 'Z': ['z'],\n",
       " 'ZH': ['s']}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn(spellings, twoLetter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6d84380-8726-4d2d-8b3c-de1c3540e629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em AH M\n",
      "aa EY EY\n",
      "ab AE B\n",
      "ac EY S IY\n",
      "ad AE D\n",
      "ae EY\n",
      "ag AE G\n",
      "ag EY G IY\n",
      "ah AA\n",
      "ai AY\n",
      "ai EY AY\n",
      "al AE L\n",
      "al AE L\n",
      "al AE L AH B AE M AH\n",
      "am AE M\n",
      "am EY EH M\n",
      "an AE N\n",
      "an AH N\n",
      "ap EY P IY\n",
      "ar AA R\n",
      "as AE Z\n",
      "as EH Z\n",
      "at AE T\n",
      "au OW\n",
      "aux OW\n",
      "av EY V IY\n",
      "aw AO\n",
      "ay EY\n",
      "ay AY\n",
      "ba B IY EY\n",
      "ba B AA\n",
      "be B IY\n",
      "be B IY\n",
      "bi B AY\n",
      "bo B OW\n",
      "by B AY\n",
      "ca K AH\n",
      "ca S IY EY\n",
      "ca K AA\n",
      "ce S IY IY\n",
      "co K OW\n",
      "co K OW\n",
      "co K AH P AH N IY\n",
      "co S IY OW T UW\n",
      "cy S AY\n",
      "da D AA\n",
      "da D IY EY\n",
      "de D IY\n",
      "de D EY\n",
      "de D AH\n",
      "di D IY\n",
      "di D AY\n",
      "do D UW\n",
      "dr D AA K T ER\n",
      "dr D R AY V\n",
      "dr D AA K T ER\n",
      "du D UW\n",
      "du D AH\n",
      "eb EH B\n",
      "ed EH D\n",
      "ee IY IY\n",
      "eh EH\n",
      "ek EH K\n",
      "ek IY K EY\n",
      "el EH L\n",
      "em EH M\n",
      "en EH N\n",
      "er ER\n",
      "es EH S\n",
      "et EH T\n",
      "ev EH V\n",
      "fe F EY\n",
      "fi F AY\n",
      "fi F IY\n",
      "fu F UW\n",
      "ga G AA\n",
      "ga JH IY EY\n",
      "ga JH AO R JH AH\n",
      "go G OW\n",
      "gu G UW\n",
      "ha HH AA\n",
      "he HH IY\n",
      "hi HH AY\n",
      "hm HH AH M\n",
      "ho HH OW\n",
      "hu HH UW\n",
      "hy HH AY\n",
      "ia IY AH\n",
      "ib IH B\n",
      "ib AY B IY\n",
      "id IH D\n",
      "id AY D IY\n",
      "if IH F\n",
      "il IH L\n",
      "im IH M\n",
      "in IH N\n",
      "in IH N\n",
      "in IH N\n",
      "in IH N CH\n",
      "io AY OW\n",
      "ip AY P IY\n",
      "ip IH P\n",
      "is IH Z\n",
      "is IH Z\n",
      "it IH T\n",
      "it IH T\n",
      "ja Y AA\n",
      "je JH IY\n",
      "ji JH IY\n",
      "jo JH OW\n",
      "jr JH UW N ER\n",
      "ju JH UW\n",
      "ka K AA\n",
      "ke K EH\n",
      "ki K IY\n",
      "ko K OW\n",
      "ku K UW\n",
      "la L AA\n",
      "le L AH\n",
      "li L IY\n",
      "ln L EY N\n",
      "lo L OW\n",
      "lu L UW\n",
      "ly L AY\n",
      "ma M AA\n",
      "mc M IH K\n",
      "mc EH M S IY\n",
      "me M IY\n",
      "mi M IY\n",
      "mo M OW\n",
      "mr M IH S T ER\n",
      "ms M IH Z\n",
      "ms M IH Z\n",
      "mt EH M T IY\n",
      "mu M UW\n",
      "my M AY\n",
      "na N AA\n",
      "ne N IY\n",
      "ne N EY\n",
      "ng EH NG\n",
      "ng IH NG\n",
      "ni N IY\n",
      "no N OW\n",
      "nu N UW\n",
      "of AH V\n",
      "of AH V\n",
      "og AA G\n",
      "oh OW\n",
      "oi OY\n",
      "oj OW JH EY\n",
      "ok OW K EY\n",
      "ol OW L\n",
      "om AO M\n",
      "on AA N\n",
      "on AO N\n",
      "op AA P\n",
      "op AO P\n",
      "or AO R\n",
      "or ER\n",
      "os AA S\n",
      "ot AO T\n",
      "ot OW T IY\n",
      "ou UW\n",
      "ow OW\n",
      "ow AW\n",
      "oy OY\n",
      "oz AA Z\n",
      "pa P AA\n",
      "pi P AY\n",
      "po P OW\n",
      "pu P UW\n",
      "qi K IY\n",
      "qu K UW\n",
      "ra R AA\n",
      "re R EY\n",
      "re R IY\n",
      "ro R OW\n",
      "ru R UW\n",
      "ru AA R Y UW\n",
      "sa S AA\n",
      "se S EY\n",
      "si S IY\n",
      "so S OW\n",
      "sr S IH S T ER\n",
      "st S T R IY T\n",
      "st S EY N T\n",
      "su S UW\n",
      "sy S AY\n",
      "ta T AA\n",
      "te T IY\n",
      "ti T IY\n",
      "to T UW\n",
      "to T IH\n",
      "to T AH\n",
      "tu T UW\n",
      "tv T EH L AH V IH ZH AH N\n",
      "ty T AY\n",
      "uh AH\n",
      "ul AH L\n",
      "um AH M\n",
      "un AH N\n",
      "un Y UW EH N\n",
      "up AH P\n",
      "ur ER\n",
      "us AH S\n",
      "us Y UW EH S\n",
      "uy UW IY\n",
      "uy Y UW W AY\n",
      "ve V IY\n",
      "vi V AY\n",
      "vi V IY\n",
      "vo V OW\n",
      "vs V ER S AH Z\n",
      "vu V UW\n",
      "vy V AY\n",
      "wa W AA\n",
      "we W IY\n",
      "wm D AH B AH Y UW EH M\n",
      "wo W OW\n",
      "wo HH W OW\n",
      "ws D AH B Y AH EH S\n",
      "wu W UW\n",
      "wy W EY\n",
      "xi SH IY\n",
      "xu Z UW\n",
      "ya Y AA\n",
      "ye Y IY\n",
      "ye Y EH\n",
      "yi Y IY\n",
      "yo Y OW\n",
      "yu Y UW\n",
      "ze Z EY\n",
      "zi Z IY\n"
     ]
    }
   ],
   "source": [
    "for i in twoLetter:\n",
    "    print(i, i.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c80e8-af96-4fe7-8060-bf138204fb67",
   "metadata": {},
   "source": [
    "10/29\n",
    "\n",
    "So. It does mostly work.\n",
    "\n",
    "But.\n",
    "\n",
    "The presence of abbreviations in the dataset means that it contains non-phonetic transcriptions. For example, one pronouncation of \"AL\" is the full phonetic spelling of Alabama.\n",
    "\n",
    "(also \"MR\" sounds like \"mister\" according to the dictionary)\n",
    "\n",
    "Currently, the code just refuses to analyze words with more phonemes than letters. This assumes that the only letter in English that can represent two distinct phones in succession is 'x', and that my attempt to account for x works. That seems to hold, though I haven't tested it on any words with more than three letters yet.\n",
    "\n",
    "I did fail to account for another edge case though: the \"\"\"word\"\"\" 'ng'. According to this version of the CMUPD, 'ng' can be pronounced 'IH NG'. This totally bypasses my attempt to check edge cases: the word is two letters long, so it doesn't have more phones than letters.\n",
    "\n",
    "LIGHTBULB MOMENT: it has no vowel letter, which means (for our purposes) it isn't a valid pronouncable English word! So I just need to find a reasonably efficient way of checking if a vowel is in a word and build that check into my code!\n",
    "\n",
    "I also plan to add a method of tracking examples of grapheme usage, which should help with explaining the solutions to its puzzles.\n",
    "\n",
    "_oh right i'm building a puzzle generator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e45c9c5-d2eb-4cb3-9add-901f183d273b",
   "metadata": {},
   "source": [
    "NOTE: this fix does not account for \"\"\"words\"\"\" like 'aa' -- pronounced /EY EY/ --, so my code learned that 'aa' is a valid spelling of /EY/. This actually does appear in fringe cases, like Baal, so maybe this is fine. Will add further comment if any other bad examples happen.\n",
    "\n",
    "Actually, \"\"\"words\"\"\" like 'er' pronounced /ER/ represent an intended example of the above result. \n",
    "\n",
    "_at least I think I intended it_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f090f17-b1cd-4e3e-ae5c-6c14f65930aa",
   "metadata": {},
   "source": [
    "Well I did find another problem word, but nothing to do with the previous comment. 'of' posed a problem. My code does not start off knowing that 'o' can be pronounced /AH/, or that 'f' can be /v/. So it can't differentiate between both new spellings, and learns that /AH/ can be spelled 'of'. I'll try just adding that pronunciation of 'o' in at the beginning, but obviously this isn't ideal, nor is it consistent. Depending on what order the dictionary of words happens to be in, it'll learn spellings at different times, potentially causing this kind of mistake for different words each time. I am also unsure at this stage whether this is an unlikely occurrence, or if I'll need to build in more knowledge beforehand, which I wanted to minimize.\n",
    "\n",
    "Also I realized I forgot to mention another issue from earlier. After running my code through every two-letter word and learning each new spelling, the lists of spellings for each phoneme were cluttered with empty strings. As a solution, I just added a function to remove those, but I need to figure out why that happens in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1cc75078-7acc-4a9e-bdee-c68d59ba39a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## from time import sleep\n",
    "from copy import copy\n",
    "\n",
    "def sideSpell(word, phones, spells, polarity):\n",
    "    currentSpell = []\n",
    "    for p in phones:\n",
    "        oldLen = len(currentSpell)\n",
    "        for s in spells[p]:\n",
    "            newSpell = copy(currentSpell)\n",
    "            if not polarity:\n",
    "                newSpell.append(s.g)\n",
    "                if word.s.startswith(''.join([a if not isinstance(a, graphExample) else a.g for a in newSpell])):\n",
    "                    currentSpell.append(s)\n",
    "                    break\n",
    "            else:\n",
    "                newSpell.insert(0, s.g)\n",
    "                if word.s.endswith(''.join([a if not isinstance(a, graphExample) else a.g for a in newSpell])):\n",
    "                    currentSpell.insert(0, s)\n",
    "                    break                \n",
    "        if len(currentSpell) == oldLen:\n",
    "            break\n",
    "    return currentSpell\n",
    "\n",
    "def spell3(word, spellings, exLen=4, debug=False):\n",
    "    word.s = word.s.lower()\n",
    "    if not word.s.isalnum():\n",
    "        if debug:\n",
    "            print(\"bad characters\", word.s)\n",
    "        return False\n",
    "    if debug:\n",
    "        print(word)\n",
    "    phones = word.p.split()\n",
    "    if len(word.s) < len(phones):\n",
    "        if debug:\n",
    "            print(\"too long!\", word.s, phones)\n",
    "        return False\n",
    "    if not set(word.s) & set('aeiouy'):\n",
    "        if debug:\n",
    "            print(\"no vowels -> not a word!\", word.s, phones)\n",
    "        return False\n",
    "    if word.s[:-2] == 'le' and phones[:-2] == ['AH', 'L'] and word.s[-3] not in ['aeiou']:\n",
    "        phones.append(phones.pop[-2])\n",
    "        if debug:\n",
    "            print(\"special case: L\")\n",
    "    rphones = copy(phones)\n",
    "    rphones.reverse()\n",
    "    if debug:\n",
    "        print(\"phones\", phones, rphones)\n",
    "    frontSpell = sideSpell(word, phones, spellings, 0)\n",
    "    frontStr = [a.g for a in frontSpell]\n",
    "    backSpell = sideSpell(word, rphones, spellings, 1)\n",
    "    backStr = [a.g for a in backSpell]\n",
    "    if debug:\n",
    "        print(\"front & back\", frontSpell, backSpell)\n",
    "    if '' in frontSpell:\n",
    "        frontSpell.remove('')\n",
    "    if '' in backSpell:\n",
    "        backSpell.remove('')\n",
    "    if frontSpell == backSpell and ''.join(frontStr) == word.s:\n",
    "        if debug:\n",
    "            print('yay!')\n",
    "            print(word, frontSpell, len(frontSpell))\n",
    "            print(backSpell, len(backSpell))\n",
    "            print(phones)\n",
    "        exPhone = choice(phones)\n",
    "        g = frontSpell[phones.index(exPhone)]\n",
    "        p = spellings[exPhone]\n",
    "        exGraph = p[p.index(g)]\n",
    "        if len(word.s) == exLen and not exGraph.set:\n",
    "            exGraph.setExample(word)\n",
    "        return True\n",
    "    missingG = graphExample(word.s.removeprefix(''.join(frontStr)).removesuffix(''.join(backStr)), isX=word.x)\n",
    "    #if not missingG.g:\n",
    "    #    missingG = backSpell[0]\n",
    "    if debug:\n",
    "        print(\"missing grapheme\", missingG)\n",
    "    if len(frontSpell + backSpell) > len(phones):\n",
    "            #print(word, frontSpell, len(frontSpell))\n",
    "            #print(backSpell, len(backSpell))\n",
    "            #print(phones)\n",
    "            if debug:\n",
    "                print(\"too long\")\n",
    "            del backSpell[0]\n",
    "    if len(frontSpell + backSpell) < len(phones):\n",
    "        try:\n",
    "            missingP = phones[len(frontSpell)]\n",
    "            if debug:\n",
    "                print(\"missing phoneme (clean)\", missingP)\n",
    "            if len(word.s) == exLen and not missingG.set:\n",
    "                missingG.setExample(word)        \n",
    "            spellings[missingP].append(missingG)    \n",
    "        except IndexError as e:\n",
    "            if debug:\n",
    "                print(word, frontSpell, len(frontSpell))\n",
    "                print(backSpell, len(backSpell))\n",
    "                print(phones)\n",
    "            raise e\n",
    "    else:\n",
    "        missingP = phones[len(frontSpell) - 1]\n",
    "        if debug:\n",
    "            print(\"missing phoneme (overlap)\", missingP)\n",
    "        try:\n",
    "            newG = graphExample(''.join((frontStr[-1], missingG.g) if frontStr else (missingG.g, backStr[0])), isX = missingG.g.count('x') or (frontStr[-1].count('x') if frontStr else backStr[0].count('x')))\n",
    "            if len(word.s) == exLen and not newG.set:\n",
    "                newG.setExample(word)  \n",
    "            spellings[missingP].append(newG)\n",
    "            if debug:\n",
    "                print(newG)\n",
    "        except IndexError as e:\n",
    "            if debug:\n",
    "                print(word, frontSpell, len(frontSpell))\n",
    "                print(backSpell, len(backSpell))\n",
    "                print(phones)\n",
    "                print(missingP)\n",
    "            raise e\n",
    "\n",
    "def learn3(spellings, words, exLen=4, debug=False):\n",
    "    newSpells = {s: copy(spellings[s]) for s in spellings}\n",
    "    for word in words:\n",
    "        spell3(word, newSpells, exLen=exLen, debug=debug)\n",
    "        if debug:\n",
    "            print(word, word.p)\n",
    "        #break\n",
    "    return newSpells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd571f7a-da85-4c1b-ad64-7f22bbc415ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(bool(set('geoff') & set('aeiou')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59960777-5ef2-4a50-8e50-535e64219a79",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "baseSpellings = {\n",
    "    'AA': ['o'],\n",
    "    'AE': ['a'],\n",
    "    'AH': ['u', 'o'],\n",
    "    'AO': ['o'],\n",
    "    'AW': ['ou'],\n",
    "    'AX': ['a'],\n",
    "    'AXR': ['er'],\n",
    "    'AY': ['i'],\n",
    "    'EH': ['e'],\n",
    "    'ER': ['ir'],\n",
    "    'EY': ['ai'],\n",
    "    'IH': ['i'],\n",
    "    'IX': ['e'],\n",
    "    'IY': ['ea'],\n",
    "    'OW': ['oa'],\n",
    "    'OY': ['oy'],\n",
    "    'UH': ['oo'],\n",
    "    'UW': ['oo'],\n",
    "    'UX': ['u'],\n",
    "    'B': ['b'],\n",
    "    'CH': ['ch'],\n",
    "    'D': ['d'],\n",
    "    'DX': ['tt'],\n",
    "    'EL': ['le'],\n",
    "    'EM': ['m'],\n",
    "    'EN': ['on'],\n",
    "    'F': ['f'],\n",
    "    'G': ['g'],\n",
    "    'H': ['h'],\n",
    "    'HH': ['h'],\n",
    "    'JH': ['j'],\n",
    "    'K': ['k'],\n",
    "    'L': ['l'],\n",
    "    'M': ['m'],\n",
    "    'N': ['n'],\n",
    "    'NX': ['ng'],\n",
    "    'NG': ['ng'],\n",
    "    'P': ['p'],\n",
    "    'Q': ['-'],\n",
    "    'R': ['r'],\n",
    "    'S': ['s'],\n",
    "    'SH': ['sh'],\n",
    "    'T': ['t'],\n",
    "    'TH': ['th'],\n",
    "    'V': ['v'],\n",
    "    'W': ['w'],\n",
    "    'WH': ['wh'],\n",
    "    'Y': ['y'],\n",
    "    'Z': ['z'],\n",
    "    'ZH': ['s']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "81a6ae4b-0cc2-4092-bdd3-03aa8435a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initSpellings(plain):\n",
    "    ans = {p: [graphExample(a, isX=bool(a.count('x'))) for a in plain[p]] for p in plain}\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7490428-7dbc-41c3-aa4c-5f366dfabea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "coolSpellings = initSpellings(baseSpellings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17a5edd0-f806-4082-a429-0a0cb9a0fbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA': ['o'],\n",
       " 'AE': ['a'],\n",
       " 'AH': ['u', 'e'],\n",
       " 'AO': ['o'],\n",
       " 'AW': ['ou'],\n",
       " 'AX': ['a'],\n",
       " 'AXR': ['er'],\n",
       " 'AY': ['i'],\n",
       " 'EH': ['e'],\n",
       " 'ER': ['ir'],\n",
       " 'EY': ['ai'],\n",
       " 'IH': ['i'],\n",
       " 'IX': ['e'],\n",
       " 'IY': ['ea'],\n",
       " 'OW': ['oa', 'o'],\n",
       " 'OY': ['oy'],\n",
       " 'UH': ['oo'],\n",
       " 'UW': ['oo'],\n",
       " 'UX': ['u'],\n",
       " 'B': ['b'],\n",
       " 'CH': ['ch'],\n",
       " 'D': ['d'],\n",
       " 'DX': ['tt'],\n",
       " 'EL': ['le'],\n",
       " 'EM': ['m'],\n",
       " 'EN': ['on'],\n",
       " 'F': ['f'],\n",
       " 'G': ['g'],\n",
       " 'H': ['h'],\n",
       " 'HH': ['h'],\n",
       " 'JH': ['j'],\n",
       " 'K': ['k'],\n",
       " 'L': ['l'],\n",
       " 'M': ['m'],\n",
       " 'N': ['n'],\n",
       " 'NX': ['ng'],\n",
       " 'NG': ['ng'],\n",
       " 'P': ['p'],\n",
       " 'Q': ['-'],\n",
       " 'R': ['r'],\n",
       " 'S': ['s'],\n",
       " 'SH': ['sh'],\n",
       " 'T': ['t'],\n",
       " 'TH': ['th'],\n",
       " 'V': ['v'],\n",
       " 'W': ['w'],\n",
       " 'WH': ['wh'],\n",
       " 'Y': ['y'],\n",
       " 'Z': ['z'],\n",
       " 'ZH': ['s']}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a05e676-750e-40a6-a2db-1da8578570a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA': [o],\n",
       " 'AE': [a],\n",
       " 'AH': [u, o],\n",
       " 'AO': [o],\n",
       " 'AW': [ou],\n",
       " 'AX': [a],\n",
       " 'AXR': [er],\n",
       " 'AY': [i],\n",
       " 'EH': [e],\n",
       " 'ER': [ir],\n",
       " 'EY': [ai],\n",
       " 'IH': [i],\n",
       " 'IX': [e],\n",
       " 'IY': [ea],\n",
       " 'OW': [oa],\n",
       " 'OY': [oy],\n",
       " 'UH': [oo],\n",
       " 'UW': [oo],\n",
       " 'UX': [u],\n",
       " 'B': [b],\n",
       " 'CH': [ch],\n",
       " 'D': [d],\n",
       " 'DX': [tt],\n",
       " 'EL': [le],\n",
       " 'EM': [m],\n",
       " 'EN': [on],\n",
       " 'F': [f],\n",
       " 'G': [g],\n",
       " 'H': [h],\n",
       " 'HH': [h],\n",
       " 'JH': [j],\n",
       " 'K': [k],\n",
       " 'L': [l],\n",
       " 'M': [m],\n",
       " 'N': [n],\n",
       " 'NX': [ng],\n",
       " 'NG': [ng],\n",
       " 'P': [p],\n",
       " 'Q': [-],\n",
       " 'R': [r],\n",
       " 'S': [s],\n",
       " 'SH': [sh],\n",
       " 'T': [t],\n",
       " 'TH': [th],\n",
       " 'V': [v],\n",
       " 'W': [w],\n",
       " 'WH': [wh],\n",
       " 'Y': [y],\n",
       " 'Z': [z],\n",
       " 'ZH': [s]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coolSpellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d3248c7-520f-483d-a877-fcf0f9743f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell3(choice(twoLetter), coolSpellings)\n",
    "clean(spellings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "22ec38e0-7f65-47f2-8c8d-d5b6dd2b8b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA': [o],\n",
       " 'AE': [a],\n",
       " 'AH': [u, o],\n",
       " 'AO': [o],\n",
       " 'AW': [ou],\n",
       " 'AX': [a],\n",
       " 'AXR': [er],\n",
       " 'AY': [i],\n",
       " 'EH': [e],\n",
       " 'ER': [ir],\n",
       " 'EY': [ai],\n",
       " 'IH': [i],\n",
       " 'IX': [e],\n",
       " 'IY': [ea],\n",
       " 'OW': [oa],\n",
       " 'OY': [oy],\n",
       " 'UH': [oo],\n",
       " 'UW': [oo],\n",
       " 'UX': [u],\n",
       " 'B': [b],\n",
       " 'CH': [ch],\n",
       " 'D': [d],\n",
       " 'DX': [tt],\n",
       " 'EL': [le],\n",
       " 'EM': [m],\n",
       " 'EN': [on],\n",
       " 'F': [f],\n",
       " 'G': [g],\n",
       " 'H': [h],\n",
       " 'HH': [h],\n",
       " 'JH': [j],\n",
       " 'K': [k, qu],\n",
       " 'L': [l],\n",
       " 'M': [m],\n",
       " 'N': [n],\n",
       " 'NX': [ng],\n",
       " 'NG': [ng],\n",
       " 'P': [p],\n",
       " 'Q': [-],\n",
       " 'R': [r],\n",
       " 'S': [s],\n",
       " 'SH': [sh],\n",
       " 'T': [t],\n",
       " 'TH': [th],\n",
       " 'V': [v],\n",
       " 'W': [w],\n",
       " 'WH': [wh],\n",
       " 'Y': [y],\n",
       " 'Z': [z],\n",
       " 'ZH': [s]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coolSpellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "872d7927-d5d6-48b5-bcf9-ee6bd4f3f554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA': ['o'],\n",
       " 'AE': ['a'],\n",
       " 'AH': ['u', 'e'],\n",
       " 'AO': ['o'],\n",
       " 'AW': ['ou'],\n",
       " 'AX': ['a'],\n",
       " 'AXR': ['er'],\n",
       " 'AY': ['i'],\n",
       " 'EH': ['e'],\n",
       " 'ER': ['ir'],\n",
       " 'EY': ['ai'],\n",
       " 'IH': ['i'],\n",
       " 'IX': ['e'],\n",
       " 'IY': ['ea'],\n",
       " 'OW': ['oa', 'o'],\n",
       " 'OY': ['oy'],\n",
       " 'UH': ['oo'],\n",
       " 'UW': ['oo'],\n",
       " 'UX': ['u'],\n",
       " 'B': ['b'],\n",
       " 'CH': ['ch'],\n",
       " 'D': ['d'],\n",
       " 'DX': ['tt'],\n",
       " 'EL': ['le'],\n",
       " 'EM': ['m'],\n",
       " 'EN': ['on'],\n",
       " 'F': ['f'],\n",
       " 'G': ['g'],\n",
       " 'H': ['h'],\n",
       " 'HH': ['h'],\n",
       " 'JH': ['j'],\n",
       " 'K': ['k'],\n",
       " 'L': ['l'],\n",
       " 'M': ['m'],\n",
       " 'N': ['n'],\n",
       " 'NX': ['ng'],\n",
       " 'NG': ['ng'],\n",
       " 'P': ['p'],\n",
       " 'Q': ['-'],\n",
       " 'R': ['r'],\n",
       " 'S': ['s'],\n",
       " 'SH': ['sh'],\n",
       " 'T': ['t'],\n",
       " 'TH': ['th'],\n",
       " 'V': ['v'],\n",
       " 'W': ['w'],\n",
       " 'WH': ['wh'],\n",
       " 'Y': ['y'],\n",
       " 'Z': ['z'],\n",
       " 'ZH': ['s']}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0eca4ae3-bdd1-4ec5-8220-d495b0000d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class graphExample:\n",
    "    def __init__(self, grapheme, isX=False):\n",
    "        self.g = grapheme\n",
    "        self.set = False\n",
    "        self.isx = isX\n",
    "        self.x = 'x' if isX else None\n",
    "\n",
    "    def __str__(self):\n",
    "        try:\n",
    "            return f\"'{self.g if not self.isx else self.x}' in '{self.w}'\"\n",
    "        except AttributeError as e:\n",
    "            return self.g if not self.isx else self.x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, str):\n",
    "            return self.g == other\n",
    "        elif isinstance(other, graphExample):\n",
    "            return self.g == other.g\n",
    "        return False\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.g.__hash__() if not self.isx else self.x.__hash__()\n",
    "\n",
    "    def setExample(self, ex):\n",
    "        self.w = ex\n",
    "        self.set = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52967d0-b782-4411-9676-bc22fbc45a0c",
   "metadata": {},
   "source": [
    "10/30\n",
    "\n",
    "Testing & Debugging\n",
    "\n",
    "Removed a leftover couple lines that didn't work with the new object system, fixed conditionals in list comprehensions\n",
    "\n",
    "Currently the grapheme objects don't account for my handling of x, so working on that now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96c4af58-4d23-49f5-8bbf-e3a15cd7189f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 1: expected str instance, graphExample found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test1 \u001b[38;5;241m=\u001b[39m \u001b[43mlearn3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoolSpellings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtwoLetter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexLen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[50], line 120\u001b[0m, in \u001b[0;36mlearn3\u001b[0;34m(spellings, words, exLen, debug)\u001b[0m\n\u001b[1;32m    118\u001b[0m newSpells \u001b[38;5;241m=\u001b[39m {s: copy(spellings[s]) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m spellings}\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[0;32m--> 120\u001b[0m     \u001b[43mspell3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewSpells\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexLen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexLen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28mprint\u001b[39m(word, word\u001b[38;5;241m.\u001b[39mp)\n",
      "Cell \u001b[0;32mIn[50], line 51\u001b[0m, in \u001b[0;36mspell3\u001b[0;34m(word, spellings, exLen, debug)\u001b[0m\n\u001b[1;32m     49\u001b[0m frontSpell \u001b[38;5;241m=\u001b[39m sideSpell(word, phones, spellings, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     50\u001b[0m frontStr \u001b[38;5;241m=\u001b[39m [a\u001b[38;5;241m.\u001b[39mg \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m frontSpell]\n\u001b[0;32m---> 51\u001b[0m backSpell \u001b[38;5;241m=\u001b[39m \u001b[43msideSpell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrphones\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspellings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m backStr \u001b[38;5;241m=\u001b[39m [a\u001b[38;5;241m.\u001b[39mg \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m backSpell]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug:\n",
      "Cell \u001b[0;32mIn[50], line 17\u001b[0m, in \u001b[0;36msideSpell\u001b[0;34m(word, phones, spells, polarity)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     newSpell\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, s\u001b[38;5;241m.\u001b[39mg)\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39ms\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraphExample\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnewSpell\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     18\u001b[0m         currentSpell\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, s)\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m                \n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 1: expected str instance, graphExample found"
     ]
    }
   ],
   "source": [
    "test1 = learn3(coolSpellings, twoLetter, exLen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "526eb3f7-4ed7-4afb-b3a4-8e8ba8609441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest1\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test1' is not defined"
     ]
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91bb6d9c-e60c-4b40-9968-0f3a7f8e19c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graphExample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## set operations and equivalency testing\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mgraphExample\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m b \u001b[38;5;241m=\u001b[39m graphExample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m adict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEE\u001b[39m\u001b[38;5;124m'\u001b[39m: [a]}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graphExample' is not defined"
     ]
    }
   ],
   "source": [
    "## set operations and equivalency testing\n",
    "\n",
    "a = graphExample('e')\n",
    "b = graphExample('e')\n",
    "adict = {'EE': [a]}\n",
    "bdict = {'EE': [b]}\n",
    "aset = set(adict['EE'])\n",
    "bset = set(bdict['EE'])\n",
    "aset ^ bset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf4efd-ef28-4cd4-ab15-c9f0fbda154e",
   "metadata": {},
   "source": [
    "I had to define the \\_\\_hash__() magic method for my graphExample objects to get set operations to work on them\n",
    "\n",
    "and then I realized I could just call the long version of symmetric_difference and keep them as lists. oh well\n",
    "\n",
    "and THEN it turns out that that method doesn't work on lists. the python library said that method works on other iterables. maybe it works on dicts or something, or maybe you can get custom objects to support it. idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a56e6-ca91-4266-abdf-e660835f4f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(spell1, spell2):\n",
    "    differences = {}\n",
    "    for phone in spell1:\n",
    "        setDiffs = set(spell1[phone]) ^ set(spell2[phone])\n",
    "        if setDiffs:\n",
    "            differences[phone] = [spell1[phone], spell2[phone]]\n",
    "    if differences:\n",
    "        return differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a817e-96d1-4e67-b391-bc8ff983b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "def get_mistakes(baseSpells, words, completeSpells, exLen=4):\n",
    "    generation = 0\n",
    "    while generation < 100:\n",
    "        testSpells = learn3(baseSpells, sample(words, len(words)), exLen=exLen)\n",
    "        check = validate(completeSpells, testSpells)\n",
    "        if check:\n",
    "            return generation, check\n",
    "        generation += 1\n",
    "    return 'nope'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032d1d8d-1b7a-4ee0-a44e-ef87b660ea26",
   "metadata": {},
   "source": [
    "I wanted to test whether this program could always find the correct spellings, or if it depended on the order. so far, it greatly depends on the order. In its current order, I only had the one exception ('of')\n",
    "\n",
    "I JUST REALIZED\n",
    "\n",
    "that shuffling affects words outside its intended scope, changing its order outside this function. that's not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eebc09-c4c9-4f4c-a7ab-e5bec88890a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell3(wordObjs2['BE'], coolSpellings, exLen=2, debug=True)\n",
    "spell3(wordObjs2['UY'], coolSpellings, exLen=2, debug=True)\n",
    "spell3(wordObjs2['VI'], coolSpellings, exLen=2, debug=True)\n",
    "\n",
    "spell3(wordObjs2['EE'], coolSpellings, exLen=2, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b69c0-3c69-439a-98ca-809723ee4f61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coolSpellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06470c7d-b17b-4867-a368-afb1a0126a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coolSpellings = initSpellings(baseSpellings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c166a6-6421-45d8-8b01-0bebe8d706e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mistakes(coolSpellings, twoLetter, test1, exLen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c2e1b-3d0a-4188-ac5c-f6b849ddcadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell3(wordObjs2['OU'], coolSpellings, exLen=2, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f673d7-4bf6-486f-a57e-2f27e0c7c4d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test2 = learn(test1, threeLetter, exLen=3, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a930cd-5559-4f3e-a384-308d8b15a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordObjs2['QU'].p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740d362a-dace-4ab9-83d8-1e92180d3871",
   "metadata": {},
   "source": [
    "After testing my model with three-letter words, I found three distinct issues:\n",
    "\n",
    "1. When my program entirely fails to spell a word with multiple sounds, it assigns the entire word to the first sound as one grapheme. This issue is not new, but still\n",
    "2. The program can find a 'correct' spelling that leaves out one or more sounds. This results in it learning to spell a sound with an empty string\n",
    "3. Once it learns that a letter can be silent, the mismatch between the number of graphemes and phonemes causes an IndexError.\n",
    "Here is an example of issues one and two: <img src=\"issue1.png\">\n",
    "And here is issue three: <img src=\"issue2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d656c9-bb8b-402c-86ca-9da686f1aba0",
   "metadata": {},
   "source": [
    "Brainstorming potential solutions:\n",
    "\n",
    "For issue one:\n",
    "<ul>\n",
    "    <li>completely ignore words which my program thinks is made of a single grapheme</li>\n",
    "    <li>do a first pass, where those words are ignored. then allow monographic words. this assumes that a later word will contain the correct spellings to fix it</li>\n",
    "</ul>\n",
    "I like the second idea, but I'm not sure if it would actually work. I suppose I could just check whether the word actually contains only one phoneme, and only allow it in that case\n",
    "\n",
    "Issue two:\n",
    "<ul>\n",
    "    <li>Figure out a way to incorporate silent letters into my program's understanding</li>\n",
    "    <li>When my program thinks it's spelled a word correctly, check if it accounts for every phoneme. If it doesn't, force it to move on</li>\n",
    "</ul>\n",
    "\n",
    "I feel like the first idea goes against what I'm trying to do here. There's no consistent way to determine which letters are silent and which aren't, and my program assumes exactly one grapheme (excepting x) for every phoneme. As for the second idea, I don't know what it'll do if it 'moves on' and then fails to spell it. I need to work that out\n",
    "\n",
    "Issue three: solve issue two\n",
    "\n",
    "Important note: I don't know which letters of the word 'ewe' make which sounds. My opinion is that the first 'e' is the /J/ sound, and the remaining 'we' represents the ending /EW/. But I don't see one correct answer. And that means I don't have an objective way to measure my program's success. That sounds like a problem, but maybe it's cool that I, in a way, made something with its own ability to interpret language and develop its own opinions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a198d8a1-9a86-4f66-891a-a87a2bd53df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## from time import sleep\n",
    "from copy import copy\n",
    "\n",
    "def sideSpell4(word, phones, spells, polarity):\n",
    "    currentSpell = []\n",
    "    for p in phones:\n",
    "        oldLen = len(currentSpell)\n",
    "        for s in spells[p]:\n",
    "            newSpell = copy(currentSpell)\n",
    "            if not polarity:\n",
    "                newSpell.append(s.g)\n",
    "                if word.s.startswith(''.join([a if not isinstance(a, graphExample) else a.g for a in newSpell])):\n",
    "                    currentSpell.append(s)\n",
    "                    break\n",
    "            else:\n",
    "                newSpell.insert(0, s.g)\n",
    "                if word.s.endswith(''.join([a if not isinstance(a, graphExample) else a.g for a in newSpell])):\n",
    "                    currentSpell.insert(0, s)\n",
    "                    break                \n",
    "        if len(currentSpell) == oldLen:\n",
    "            break\n",
    "    return currentSpell\n",
    "\n",
    "def spell4(word, spellings, exLen=4, debug=False):\n",
    "    word.s = word.s.lower()\n",
    "    if not word.s.isalnum():\n",
    "        if debug:\n",
    "            print(\"bad characters\", word.s)\n",
    "        return False\n",
    "    if debug:\n",
    "        print(word)\n",
    "    phones = word.p.split()\n",
    "    if len(word.s) < len(phones):\n",
    "        if debug:\n",
    "            print(\"too long!\", word.s, phones)\n",
    "        return False\n",
    "    if not set(word.s) & set('aeiouy'):\n",
    "        if debug:\n",
    "            print(\"no vowels -> not a word!\", word.s, phones)\n",
    "        return False\n",
    "    if word.s[:-2] == 'le' and phones[:-2] == ['AH', 'L'] and word.s[-3] not in ['aeiou']:\n",
    "        phones.append(phones.pop[-2])\n",
    "        if debug:\n",
    "            print(\"special case: L\")\n",
    "    rphones = copy(phones)\n",
    "    rphones.reverse()\n",
    "    if debug:\n",
    "        print(\"phones\", phones, rphones)\n",
    "    frontSpell = sideSpell4(word, phones, spellings, 0)\n",
    "    frontStr = [a.g for a in frontSpell]\n",
    "    backSpell = sideSpell4(word, rphones, spellings, 1)\n",
    "    backStr = [a.g for a in backSpell]\n",
    "    if debug:\n",
    "        print(\"front & back\", frontSpell, backSpell)\n",
    "    if '' in frontSpell:\n",
    "        frontSpell.remove('')\n",
    "    if '' in backSpell:\n",
    "        backSpell.remove('')\n",
    "    if len(phones) > (len(frontSpell) + len(backSpell) + 1):\n",
    "        if debug:\n",
    "            print(\"failure to spell\")\n",
    "        return False\n",
    "    if frontSpell == backSpell and ''.join(frontStr) == word.s:\n",
    "        if debug:\n",
    "            print('yay!')\n",
    "            print(word, frontSpell, len(frontSpell))\n",
    "            print(backSpell, len(backSpell))\n",
    "            print(phones)\n",
    "        exPhone = choice(phones)\n",
    "        g = frontSpell[phones.index(exPhone)]\n",
    "        p = spellings[exPhone]\n",
    "        exGraph = p[p.index(g)]\n",
    "        if len(word.s) == exLen and not exGraph.set:\n",
    "            exGraph.setExample(word)\n",
    "        return True\n",
    "    missingG = graphExample(word.s.removeprefix(''.join(frontStr)).removesuffix(''.join(backStr)), isX=word.x)\n",
    "    #if not missingG.g:\n",
    "    #    missingG = backSpell[0]\n",
    "    if debug:\n",
    "        print(\"missing grapheme\", missingG)\n",
    "    if len(frontSpell + backSpell) > len(phones):\n",
    "            #print(word, frontSpell, len(frontSpell))\n",
    "            #print(backSpell, len(backSpell))\n",
    "            #print(phones)\n",
    "            if debug:\n",
    "                print(\"too long\")\n",
    "            del backSpell[0]\n",
    "    if len(frontSpell + backSpell) < len(phones):\n",
    "        try:\n",
    "            missingP = phones[len(frontSpell)]\n",
    "            if debug:\n",
    "                print(\"missing phoneme (clean)\", missingP)\n",
    "            if len(word.s) == exLen and not missingG.set:\n",
    "                missingG.setExample(word)        \n",
    "            spellings[missingP].append(missingG)    \n",
    "        except IndexError as e:\n",
    "            if debug:\n",
    "                print(word, frontSpell, len(frontSpell))\n",
    "                print(backSpell, len(backSpell))\n",
    "                print(phones)\n",
    "            raise e\n",
    "    else:\n",
    "        missingP = phones[len(frontSpell) - 1]\n",
    "        if debug:\n",
    "            print(\"missing phoneme (overlap)\", missingP)\n",
    "        try:\n",
    "            newG = graphExample(''.join((frontStr[-1], missingG.g) if frontStr else (missingG.g, backStr[0])), isX = missingG.g.count('x') or (frontStr[-1].count('x') if frontStr else backStr[0].count('x')))\n",
    "            if len(word.s) == exLen and not newG.set:\n",
    "                newG.setExample(word)  \n",
    "            spellings[missingP].append(newG)\n",
    "            if debug:\n",
    "                print(newG)\n",
    "        except IndexError as e:\n",
    "            if debug:\n",
    "                print(word, frontSpell, len(frontSpell))\n",
    "                print(backSpell, len(backSpell))\n",
    "                print(phones)\n",
    "                print(missingP)\n",
    "            raise e\n",
    "\n",
    "def learn3(spellings, words, exLen=4, debug=False):\n",
    "    newSpells = {s: copy(spellings[s]) for s in spellings}\n",
    "    for word in words:\n",
    "        spell3(word, newSpells, exLen=exLen, debug=debug)\n",
    "        if debug:\n",
    "            print(word, word.p)\n",
    "        #break\n",
    "    return newSpells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "da49dfc5-0e4f-4639-a9d6-79c2c050e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGLen(word):\n",
    "    pNum = len(word.p.split())\n",
    "    lNum = len(word.s)\n",
    "    minG = (lNum / pNum)\n",
    "    if minG > 4:\n",
    "        raise ValueError(\"too many letters\")\n",
    "    if minG < 1:\n",
    "        raise ValueError(\"too many phonemes\")\n",
    "    minG = int(minG)\n",
    "    maxG = min(lNum - pNum + 1, 4)\n",
    "    return (maxG, minG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "faf721bc-17d2-49a7-8820-d46a4718b2b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many phonemes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgetGLen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwordObjs2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDR.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[69], line 8\u001b[0m, in \u001b[0;36mgetGLen\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoo many letters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m minG \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoo many phonemes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m minG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(minG)\n\u001b[1;32m     10\u001b[0m maxG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(lNum \u001b[38;5;241m-\u001b[39m pNum \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many phonemes"
     ]
    }
   ],
   "source": [
    "getGLen(wordObjs2['DR.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ce63bafd-c916-4d7d-ac2c-a9c93f48358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atomize(word):\n",
    "    maxGraph, minGraph = getGLen(word)\n",
    "    lIndex = 0\n",
    "    potential = []\n",
    "    while lIndex < len(word.s):\n",
    "        for i in range(minGraph, maxGraph + 1):\n",
    "            atom = \"*\" * lIndex\n",
    "            atom += word.s[lIndex:lIndex + i]\n",
    "            atom += \"*\" * (len(word.s) - len(atom))\n",
    "            if atom not in potential:\n",
    "                potential.append(atom)\n",
    "        lIndex += 1\n",
    "    return potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7d33a687-aea9-4164-90d3-81d913ac61ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b*****',\n",
       " 'br****',\n",
       " 'bre***',\n",
       " '*r****',\n",
       " '*re***',\n",
       " '*rea**',\n",
       " '**e***',\n",
       " '**ea**',\n",
       " '**eat*',\n",
       " '***a**',\n",
       " '***at*',\n",
       " '***ath',\n",
       " '****t*',\n",
       " '****th',\n",
       " '*****h']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomize(wordObjs2['BREATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ddf1b390-bcce-4e4c-8135-4e079e50ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from math import ceil\n",
    "\n",
    "def match_phones(word):\n",
    "    graphs = atomize(word)\n",
    "    phones = word.p.split()\n",
    "    print(phones)\n",
    "    matches = {}\n",
    "    grange = range(len(graphs))\n",
    "    for p in phones:\n",
    "        matches[p] = []\n",
    "    for gInd in grange:\n",
    "        g = graphs[gInd]\n",
    "        if g.lstrip('*') == g:\n",
    "            matches[phones[0]].append(g.strip('*'))\n",
    "        elif g.rstrip('*') == g:\n",
    "            matches[phones[len(phones) - 1]].append(g.strip('*'))\n",
    "        else:\n",
    "            a = re.split('\\w', g)\n",
    "            endGaps = len(a[len(a) - 1])\n",
    "            absMin = ceil(len(a[0]) / getGLen(word)[0])\n",
    "            endPhones = len(phones[absMin + 1:])\n",
    "            pmin = absMin + (endPhones - endGaps if endGaps < endPhones else 0)\n",
    "            #pmax = max(len(a[0]) - ceil(endGaps / getGLen(word)[0]), 1)\n",
    "            absMax = ceil(endGaps / getGLen(word)[0])\n",
    "            pmax = min(len(phones) - 2, len(a[0]))\n",
    "            #pmax = min(len(a[0]), len(phones))\n",
    "            print(g, pmin, pmax)\n",
    "            for p1 in phones[pmin: pmax + 1]:\n",
    "                matches[p1].append(g.strip('*'))\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3220f0fc-56e0-4e46-ad91-3e7f50d02bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'R', 'EH', 'TH']\n",
      "*r**** 1 1\n",
      "*re*** 1 1\n",
      "*rea** 1 1\n",
      "**e*** 1 2\n",
      "**ea** 1 2\n",
      "**eat* 2 2\n",
      "***a** 1 2\n",
      "***at* 2 2\n",
      "****t* 2 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'B': ['b', 'br', 'bre'],\n",
       " 'R': ['r', 're', 'rea', 'e', 'ea', 'a'],\n",
       " 'EH': ['e', 'ea', 'eat', 'a', 'at', 't'],\n",
       " 'TH': ['ath', 'th', 'h']}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breath = wordObjs2['BREATH']\n",
    "\n",
    "match_phones(breath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8261fd29-d409-4160-8015-7bc4db27e43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'R', 'EH', 'TH', 'IY']\n",
      "*r***** 1 1\n",
      "*re**** 1 1\n",
      "*rea*** 1 1\n",
      "**e**** 1 2\n",
      "**ea*** 1 2\n",
      "**eat** 2 2\n",
      "***a*** 1 3\n",
      "***at** 2 3\n",
      "***ath* 3 3\n",
      "****t** 2 3\n",
      "****th* 3 3\n",
      "*****h* 3 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'B': ['b', 'br', 'bre'],\n",
       " 'R': ['r', 're', 'rea', 'e', 'ea', 'a'],\n",
       " 'EH': ['e', 'ea', 'eat', 'a', 'at', 't'],\n",
       " 'TH': ['a', 'at', 'ath', 't', 'th', 'h'],\n",
       " 'IY': ['thy', 'hy', 'y']}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breathy = wordObjs2['BREATHY']\n",
    "\n",
    "match_phones(breathy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "62773108-c16a-4545-9d93-ba5084c4c5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'R', 'IY', 'DH', 'IH', 'NG']\n",
      "*r******* 1 1\n",
      "*re****** 1 1\n",
      "*rea***** 1 1\n",
      "*reat**** 1 1\n",
      "**e****** 1 2\n",
      "**ea***** 1 2\n",
      "**eat**** 1 2\n",
      "**eath*** 2 2\n",
      "***a***** 1 3\n",
      "***at**** 1 3\n",
      "***ath*** 2 3\n",
      "***athi** 3 3\n",
      "****t**** 1 4\n",
      "****th*** 2 4\n",
      "****thi** 3 4\n",
      "****thin* 4 4\n",
      "*****h*** 2 4\n",
      "*****hi** 3 4\n",
      "*****hin* 4 4\n",
      "******i** 3 4\n",
      "******in* 4 4\n",
      "*******n* 4 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'B': ['b', 'br', 'bre', 'brea'],\n",
       " 'R': ['r', 're', 'rea', 'reat', 'e', 'ea', 'eat', 'a', 'at', 't'],\n",
       " 'IY': ['e', 'ea', 'eat', 'eath', 'a', 'at', 'ath', 't', 'th', 'h'],\n",
       " 'DH': ['a', 'at', 'ath', 'athi', 't', 'th', 'thi', 'h', 'hi', 'i'],\n",
       " 'IH': ['t', 'th', 'thi', 'thin', 'h', 'hi', 'hin', 'i', 'in', 'n'],\n",
       " 'NG': ['hing', 'ing', 'ng', 'g']}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breathing = wordObjs2['BREATHING']\n",
    "\n",
    "match_phones(breathing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ed36e928-295c-4c8e-b26d-712756fa46f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n",
      "_\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('***ertyui', '', '')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,3,4]\n",
    "print(l[1:7])\n",
    "print(\"_\"*1)\n",
    "'***ertyui'.partition('tqweryuiopasdfghjklzxcvbnm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1f9bc8-e045-4e01-8510-e14d4c676588",
   "metadata": {},
   "source": [
    "11/7\n",
    "\n",
    "<h1>What I want</h1>\n",
    "a way to determine how each phoneme in a word is spelled\n",
    "<h2>What is the scope?</h2>\n",
    "most English words, excepting obscure scientific/technical terms, foreign words directly borrowed (like names), and abbreviations\n",
    "<h2>What other goals did I want to incorporate?</h2>\n",
    "Involve as little interference from me as possible, like coding in exceptions for irregular words\n",
    "<h2>How have I attempted to realize this idea?</h2>\n",
    "<ol>\n",
    "    <li>determine spellings via deduction, ie. use a series of logical decisions and processes that can determine the spelling of every English word</li>\n",
    "    <li>start with some basic graphemes for each phoneme, and analyze each word, learning new phonemes along the way</li>\n",
    "    <li>(WIP) using the known number and order of phonemes, calculate each possible representation of phonemes in every word and do something with them</li>\n",
    "</ol>\n",
    "<h2>Issues with each attempt:</h2>\n",
    "<ol>\n",
    "    <li>too many irregular English words to do this, as far as I can tell</li>\n",
    "    <li>My code assumed that each word would have no more than one new grapheme, which did not hold. If there's more than one new grapheme, my code can't tell where one ends and the other begins. Also, the code found false positives, resulting in it learning blank graphemes, which then cause a catastrophic error</li>\n",
    "    <li>It's unclear how this helps me. One idea was to keep the most common graphemes, but that both leaves out real graphemes that only occur once and includes common mistakes. I like how it accounts for uncertainty, but it needs more time to cure. Also, it currently doesn't handle the '-le' exception.</li>\n",
    "    <ul>\n",
    "        <li>Actually, that's only part of the problem. When a sound occurs more than once within a word, it doesn't keep track of their representations separately. This may be a problem, or maybe this is a desired outcome. I'm not sure yet.</li>\n",
    "    </ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c55167e8-849c-4956-be2c-6d889c2a3ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'IH', 'T', 'AH', 'L']\n",
      "*i**** 1 1\n",
      "*it*** 1 1\n",
      "**t*** 1 2\n",
      "**tt** 2 2\n",
      "***t** 2 3\n",
      "***tl* 3 3\n",
      "****l* 3 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'L': ['l', 'li', 'le', 'e'],\n",
       " 'IH': ['i', 'it', 't'],\n",
       " 'T': ['t', 'tt', 't'],\n",
       " 'AH': ['t', 'tl', 'l']}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_phones(wordObjs2['LITTLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0f464649-0565-4382-962b-64032983d21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K', 'IH', 'B', 'AH', 'L']\n",
      "*i**** 1 1\n",
      "*ib*** 1 1\n",
      "**b*** 1 2\n",
      "**bb** 2 2\n",
      "***b** 2 3\n",
      "***bl* 3 3\n",
      "****l* 3 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'K': ['k', 'ki'],\n",
       " 'IH': ['i', 'ib', 'b'],\n",
       " 'B': ['b', 'bb', 'b'],\n",
       " 'AH': ['b', 'bl', 'l'],\n",
       " 'L': ['le', 'e']}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_phones(wordObjs2['KIBBLE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa169a47-26d9-42dd-bb19-2708a0c05524",
   "metadata": {},
   "source": [
    "How should my code distinguish between correct and incorrect graphemes?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "18191743-acec-4afc-938d-6076ca9f62d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from math import ceil\n",
    "\n",
    "def match_phones2(word):\n",
    "    graphs = atomize(word)\n",
    "    phones = word.p.split()\n",
    "    print(phones)\n",
    "    matches = {}\n",
    "    grange = range(len(graphs))\n",
    "    for p in phones:\n",
    "        matches[p] = []\n",
    "    for gInd in grange:\n",
    "        g = graphs[gInd]\n",
    "        if g.lstrip('*') == g:\n",
    "            matches[phones[0]].append(g)\n",
    "        elif g.rstrip('*') == g:\n",
    "            matches[phones[len(phones) - 1]].append(g)\n",
    "        else:\n",
    "            a = re.split('\\w', g)\n",
    "            endGaps = len(a[len(a) - 1])\n",
    "            absMin = ceil(len(a[0]) / getGLen(word)[0])\n",
    "            endPhones = len(phones[absMin + 1:])\n",
    "            pmin = absMin + (endPhones - endGaps if endGaps < endPhones else 0)\n",
    "            #pmax = max(len(a[0]) - ceil(endGaps / getGLen(word)[0]), 1)\n",
    "            absMax = ceil(endGaps / getGLen(word)[0])\n",
    "            pmax = min(len(phones) - 2, len(a[0]))\n",
    "            #pmax = min(len(a[0]), len(phones))\n",
    "            print(g, pmin, pmax)\n",
    "            for p1 in phones[pmin: pmax + 1]:\n",
    "                matches[p1].append(g)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5bb4aa31-6fcc-4792-87f2-501d066bfd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'R', 'EH', 'TH']\n",
      "*r**** 1 1\n",
      "*re*** 1 1\n",
      "*rea** 1 1\n",
      "**e*** 1 2\n",
      "**ea** 1 2\n",
      "**eat* 2 2\n",
      "***a** 1 2\n",
      "***at* 2 2\n",
      "****t* 2 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'B': ['b*****', 'br****', 'bre***'],\n",
       " 'R': ['*r****', '*re***', '*rea**', '**e***', '**ea**', '***a**'],\n",
       " 'EH': ['**e***', '**ea**', '**eat*', '***a**', '***at*', '****t*'],\n",
       " 'TH': ['***ath', '****th', '*****h']}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breathPhones = match_phones2(breath)\n",
    "breathPhones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b1431478-640a-4e44-b874-4881460ec4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_spaces(word, reverse=False):\n",
    "    letters = list(word)\n",
    "    count = 0\n",
    "    #print(word)\n",
    "    #print(letters)\n",
    "    if reverse:\n",
    "        while letters.pop() == '*':\n",
    "            count += 1\n",
    "    else:\n",
    "        while letters.pop(0) == '*':\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def count_letters(word):\n",
    "    letters = list(word)\n",
    "    count = 0\n",
    "    while len(letters) != 0 and letters.pop(0) != '*':\n",
    "        count += 1\n",
    "    return count\n",
    "    \n",
    "def stitch(matches):\n",
    "    stitched = matches.pop(0)\n",
    "    mapping = [0] * (len(stitched) - count_spaces(stitched, reverse=True))\n",
    "    num = 1\n",
    "    for grapheme in matches:\n",
    "        start = count_spaces(grapheme)\n",
    "        end = count_spaces(grapheme, reverse=True)\n",
    "        if start != len(stitched.strip('*')):\n",
    "            raise ValueError('bad match')\n",
    "        stitched = stitched.strip('*') + grapheme.lstrip('*')\n",
    "        newLetterNum = count_letters(grapheme.lstrip('*'))\n",
    "        mapping += [num] * newLetterNum\n",
    "        num += 1\n",
    "    return stitched, mapping\n",
    "\n",
    "def fancyPrint(stitchObj):\n",
    "    print(stitchObj[0])\n",
    "    print(''.join([str(i) for i in stitchObj[1]]))\n",
    "\n",
    "def recursionPractice(listOfLists):\n",
    "    return stitch(['something', recursionPractice('something else')])\n",
    "\n",
    "def combinatory(length, bases):\n",
    "    combs = []\n",
    "    \n",
    "\n",
    "def getIndices(matchDict):\n",
    "    lengths = [len(matchDict[i]) for i in matchDict]\n",
    "    indices = []\n",
    "    pass\n",
    "\n",
    "def stitchAll(matchDict, phoneInds, graphInds):\n",
    "    phones = matchDict.keys()\n",
    "    for graph in matchDict[phone]:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "40baf332-0078-4526-93b1-3044570537aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b*****\n",
      "['*', '*', '*', '*', '*']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_spaces(breathPhones['B'][0], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "db8cb37f-1a4c-46df-954b-92de5f348eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('breath', [0, 1, 2, 3, 3, 3])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = stitch([breathPhones['B'][0], breathPhones['R'][0], breathPhones['EH'][0], breathPhones['TH'][0]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "54b10fa7-5d93-4993-88cb-2616fe4a786d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breath\n",
      "012333\n"
     ]
    }
   ],
   "source": [
    "print(a[0])\n",
    "print(''.join([str(i) for i in a[1]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
