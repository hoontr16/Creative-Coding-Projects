{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27630b72-2f15-457c-a0ef-eaa2a4012f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!EXCLAMATION-POINT  EH2 K S K L AH0 M EY1 SH AH0 N P OY2 N T\n"
     ]
    }
   ],
   "source": [
    "with open('cmuDict.txt', 'r', encoding='utf-8') as f:\n",
    "    rawDict = f.read()\n",
    "\n",
    "cmu = rawDict.split('\\n')[56:]\n",
    "print(cmu[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35883876-72ba-4649-b5c6-a40063cd7ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = [    # General American English specifically\n",
    "    'AA',     # balm, bot\n",
    "    'AE',     # bat\n",
    "    'AH',     # butt\n",
    "    'AO',     # stOry      this gave me a heart attack when Wikipedia gave another example as 'cAUGHt' which is not at all the same sound to me\n",
    "    'AW',     # bout\n",
    "    'AX',     # commA (schwa)\n",
    "    'AY',     # bite\n",
    "    'EH',     # bet\n",
    "    'ER',     # bIRd, forewORd\n",
    "    'EY',     # bait\n",
    "    'IH',     # bit\n",
    "    'IX',     # rosEs, rabbIt\n",
    "    'IY',     # beat\n",
    "    'OW',     # boat\n",
    "    'OY',     # boy\n",
    "    'UH',     # book\n",
    "    'UW'      # boot\n",
    "]\n",
    "# source: https://en.wikipedia.org/wiki/ARPABET\n",
    "consonants = [\n",
    "    'B',      # buy\n",
    "    'CH',     # China\n",
    "    'D',      # die\n",
    "    'DH',     # thy\n",
    "    'DX',     # buTTer\n",
    "    'EL',     # bottLE\n",
    "    'EM',     # rhythM\n",
    "    'EN',     # buttON\n",
    "    'F',      # fight\n",
    "    'G',      # guy\n",
    "    'HH',     # High\n",
    "    'JH',     # jive\n",
    "    'K',      # kite\n",
    "    'L',      # lie\n",
    "    'M',      # my\n",
    "    'N',      # nigh\n",
    "    'NG',     # siNG\n",
    "    'P',      # pie\n",
    "    'Q',      # uh-oh (glottal stop)\n",
    "    'R',      # rye\n",
    "    'S',      # sigh\n",
    "    'SH',     # shy\n",
    "    'T',      # tie\n",
    "    'TH',     # thigh\n",
    "    'V',      # vie\n",
    "    'W',      # wise\n",
    "    'WH',     # why (for fancy people)\n",
    "    'Y',      # yacht\n",
    "    'Z',      # zoo\n",
    "    'ZH'      # pleaSure\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880f4bce-24f4-4893-add6-b6183fc682fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class coolWord:\n",
    "    def __init__(self, spelling, pronounciation):\n",
    "        symbols = \"~!@#$%^&*()-_=+[]{}\\\\|;:\\'\\\",<.>/?1234567890\"\n",
    "        self.word = spelling.strip(symbols).lower()\n",
    "        ps = pronounciation.split()\n",
    "        ps2 = [p.strip(symbols) for p in ps]\n",
    "        self.p = ' '.join(ps2)        \n",
    "        self.x = False\n",
    "        self.xx = False\n",
    "        self.xIndex = 0\n",
    "        if 'x' in self.word:\n",
    "            self.x = True\n",
    "            if 'xx' in self.word:\n",
    "                self.xx = True\n",
    "                self.s = self.word.replace('xx', 'ks')\n",
    "            else:\n",
    "                self.xIndex = self.word.index('x')\n",
    "                if self.xIndex == 0:\n",
    "                    self.s = self.word.replace('x', 'z')\n",
    "                elif self.xIndex == len(self.word) - 1 and ps2[-1] == 'OW':\n",
    "                    self.s = self.word.replace('x', '')\n",
    "                elif self.word[self.xIndex - 1] in 'aeiou' and self.xIndex != len(self.word) - 1 and self.word[self.xIndex + 1] in 'aeiou':\n",
    "                    self.s = self.word.replace('x', 'gz')\n",
    "                else:\n",
    "                    self.s = self.word.replace('x', 'ks')\n",
    "        else:\n",
    "            self.s = self.word\n",
    "    def __str__(self):\n",
    "        return self.word\n",
    "    def __repr__(self):\n",
    "        return self.word\n",
    "    def atomize(self, v, c):\n",
    "        current_letters = []\n",
    "        current_sounds = []\n",
    "        final = {}\n",
    "        vows = []\n",
    "        cons = []\n",
    "        letter_counter = 0\n",
    "        while letter_counter < len(self.s):\n",
    "            current_letter = letter_counter\n",
    "            while letter_counter < len(self.s) and self.s[letter_counter] in \"qwrtypsdfghjklzxcvbnm\":\n",
    "                current_letters.append(self.s[letter_counter])\n",
    "                letter_counter += 1\n",
    "            final[current_letter] = ''.join(current_letters)\n",
    "            current_letters = []\n",
    "            if letter_counter >= len(self.s):\n",
    "                break\n",
    "            current_letter = letter_counter\n",
    "            while letter_counter < len(self.s) and self.s[letter_counter] in \"aeiou\":\n",
    "                current_letters.append(self.s[letter_counter])\n",
    "                letter_counter += 1\n",
    "            final[current_letter] = ''.join(current_letters)\n",
    "            current_letters = []\n",
    "        self.c = cons\n",
    "        self.v = vows\n",
    "        self.f = final\n",
    "#        for i in self.p:\n",
    "#            if i in v:\n",
    "#                pass\n",
    "#            elif i in c:\n",
    "#                current_sounds.append(i)\n",
    "#                self.c[letter_counter].append(current_letters)\n",
    "#                letter_counter += 1\n",
    "#            else:\n",
    "#                print(\"weirdo ->\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5742add1-f562-425d-be46-41414fb09570",
   "metadata": {},
   "outputs": [],
   "source": [
    "## from time import sleep\n",
    "from copy import copy\n",
    "\n",
    "def sideSpell(word, phones, spells, polarity):\n",
    "    currentSpell = []\n",
    "    for p in phones:\n",
    "        oldLen = len(currentSpell)\n",
    "        for s in spells[p]:\n",
    "            newSpell = copy(currentSpell)\n",
    "            if not polarity:\n",
    "                newSpell.append(s.g)\n",
    "                if word.s.startswith(''.join([a if not isinstance(a, graphExample) else a.g for a in newSpell])):\n",
    "                    currentSpell.append(s)\n",
    "                    break\n",
    "            else:\n",
    "                newSpell.insert(0, s.g)\n",
    "                if word.s.endswith(''.join([a if not isinstance(a, graphExample) else a.g for a in newSpell])):\n",
    "                    currentSpell.insert(0, s)\n",
    "                    break                \n",
    "        if len(currentSpell) == oldLen:\n",
    "            break\n",
    "    return currentSpell\n",
    "\n",
    "def spell3(word, spellings, exLen=4, debug=False):\n",
    "    word.s = word.s.lower()\n",
    "    if not word.s.isalnum():\n",
    "        if debug:\n",
    "            print(\"bad characters\", word.s)\n",
    "        return False\n",
    "    if debug:\n",
    "        print(word)\n",
    "    phones = word.p.split()\n",
    "    if len(word.s) < len(phones):\n",
    "        if debug:\n",
    "            print(\"too long!\", word.s, phones)\n",
    "        return False\n",
    "    if not set(word.s) & set('aeiouy'):\n",
    "        if debug:\n",
    "            print(\"no vowels -> not a word!\", word.s, phones)\n",
    "        return False\n",
    "    if word.s[:-2] == 'le' and phones[:-2] == ['AH', 'L'] and word.s[-3] not in ['aeiou']:\n",
    "        phones.append(phones.pop[-2])\n",
    "        if debug:\n",
    "            print(\"special case: L\")\n",
    "    rphones = copy(phones)\n",
    "    rphones.reverse()\n",
    "    if debug:\n",
    "        print(\"phones\", phones, rphones)\n",
    "    frontSpell = sideSpell(word, phones, spellings, 0)\n",
    "    frontStr = [a.g for a in frontSpell]\n",
    "    backSpell = sideSpell(word, rphones, spellings, 1)\n",
    "    backStr = [a.g for a in backSpell]\n",
    "    if debug:\n",
    "        print(\"front & back\", frontSpell, backSpell)\n",
    "    if '' in frontSpell:\n",
    "        frontSpell.remove('')\n",
    "    if '' in backSpell:\n",
    "        backSpell.remove('')\n",
    "    if frontSpell == backSpell and ''.join(frontStr) == word.s:\n",
    "        if debug:\n",
    "            print('yay!')\n",
    "            print(word, frontSpell, len(frontSpell))\n",
    "            print(backSpell, len(backSpell))\n",
    "            print(phones)\n",
    "        exPhone = choice(phones)\n",
    "        g = frontSpell[phones.index(exPhone)]\n",
    "        p = spellings[exPhone]\n",
    "        exGraph = p[p.index(g)]\n",
    "        if len(word.s) == exLen and not exGraph.set:\n",
    "            exGraph.setExample(word)\n",
    "        return True\n",
    "    missingG = graphExample(word.s.removeprefix(''.join(frontStr)).removesuffix(''.join(backStr)), isX=word.x)\n",
    "    #if not missingG.g:\n",
    "    #    missingG = backSpell[0]\n",
    "    if debug:\n",
    "        print(\"missing grapheme\", missingG)\n",
    "    if len(frontSpell + backSpell) > len(phones):\n",
    "            #print(word, frontSpell, len(frontSpell))\n",
    "            #print(backSpell, len(backSpell))\n",
    "            #print(phones)\n",
    "            if debug:\n",
    "                print(\"too long\")\n",
    "            del backSpell[0]\n",
    "    if len(frontSpell + backSpell) < len(phones):\n",
    "        try:\n",
    "            missingP = phones[len(frontSpell)]\n",
    "            if debug:\n",
    "                print(\"missing phoneme (clean)\", missingP)\n",
    "            if len(word.s) == exLen and not missingG.set:\n",
    "                missingG.setExample(word)        \n",
    "            spellings[missingP].append(missingG)    \n",
    "        except IndexError as e:\n",
    "            if debug:\n",
    "                print(word, frontSpell, len(frontSpell))\n",
    "                print(backSpell, len(backSpell))\n",
    "                print(phones)\n",
    "            raise e\n",
    "    else:\n",
    "        missingP = phones[len(frontSpell) - 1]\n",
    "        if debug:\n",
    "            print(\"missing phoneme (overlap)\", missingP)\n",
    "        try:\n",
    "            newG = graphExample(''.join((frontStr[-1], missingG.g) if frontStr else (missingG.g, backStr[0])), isX = missingG.g.count('x') or (frontStr[-1].count('x') if frontStr else backStr[0].count('x')))\n",
    "            if len(word.s) == exLen and not newG.set:\n",
    "                newG.setExample(word)  \n",
    "            spellings[missingP].append(newG)\n",
    "            if debug:\n",
    "                print(newG)\n",
    "        except IndexError as e:\n",
    "            if debug:\n",
    "                print(word, frontSpell, len(frontSpell))\n",
    "                print(backSpell, len(backSpell))\n",
    "                print(phones)\n",
    "                print(missingP)\n",
    "            raise e\n",
    "\n",
    "def learn3(spellings, words, exLen=4, debug=False):\n",
    "    newSpells = {s: copy(spellings[s]) for s in spellings}\n",
    "    for word in words:\n",
    "        spell3(word, newSpells, exLen=exLen, debug=debug)\n",
    "        if debug:\n",
    "            print(word, word.p)\n",
    "        #break\n",
    "    return newSpells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68d5c204-f411-4073-929a-3633efc56109",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordObjs2 = {line.split(maxsplit=1)[0]: coolWord(*line.split(maxsplit=1)) for line in cmu}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "575daeab-4bce-4c9b-a907-0fe800715fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spellings = {\n",
    "    'AA': ['o'],\n",
    "    'AE': ['a'],\n",
    "    'AH': ['u'],\n",
    "    'AO': ['o'],\n",
    "    'AW': ['ou'],\n",
    "    'AX': ['a'],\n",
    "    'AXR': ['er'],\n",
    "    'AY': ['i'],\n",
    "    'EH': ['e'],\n",
    "    'ER': ['ir'],\n",
    "    'EY': ['ai'],\n",
    "    'IH': ['i'],\n",
    "    'IX': ['e'],\n",
    "    'IY': ['ea'],\n",
    "    'OW': ['oa'],\n",
    "    'OY': ['oy'],\n",
    "    'UH': ['oo'],\n",
    "    'UW': ['oo'],\n",
    "    'UX': ['u'],\n",
    "    'B': ['b'],\n",
    "    'CH': ['ch'],\n",
    "    'D': ['d'],\n",
    "    'DX': ['tt'],\n",
    "    'EL': ['le'],\n",
    "    'EM': ['m'],\n",
    "    'EN': ['on'],\n",
    "    'F': ['f'],\n",
    "    'G': ['g'],\n",
    "    'H': ['h'],\n",
    "    'HH': ['h'],\n",
    "    'JH': ['j'],\n",
    "    'K': ['k'],\n",
    "    'L': ['l'],\n",
    "    'M': ['m'],\n",
    "    'N': ['n'],\n",
    "    'NX': ['ng'],\n",
    "    'NG': ['ng'],\n",
    "    'P': ['p'],\n",
    "    'Q': ['-'],\n",
    "    'R': ['r'],\n",
    "    'S': ['s'],\n",
    "    'SH': ['sh'],\n",
    "    'T': ['t'],\n",
    "    'TH': ['th'],\n",
    "    'V': ['v'],\n",
    "    'W': ['w'],\n",
    "    'WH': ['wh'],\n",
    "    'Y': ['y'],\n",
    "    'Z': ['z'],\n",
    "    'ZH': ['s']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6e94256-88c9-48f6-b21d-c348000a1f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "threeLetter = [wordObjs2[word] for word in wordObjs2 if len(wordObjs2[word].s) == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bbcbbc9-ccc7-4876-ba28-5d46f56e3389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1733"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(threeLetter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10fb8942-b4fa-4935-a041-f763d6314a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "twoLetter = [wordObjs2[word] for word in wordObjs2 if len(wordObjs2[word].s) == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "563d4157-c575-4110-9616-d552d3c0e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## from time import sleep\n",
    "from copy import copy\n",
    "\n",
    "def sideSpell4(word, phones, spells, polarity):\n",
    "    currentSpell = []\n",
    "    for p in phones:\n",
    "        oldLen = len(currentSpell)\n",
    "        for s in spells[p]:\n",
    "            newSpell = copy(currentSpell)\n",
    "            if not polarity:\n",
    "                newSpell.append(s.g)\n",
    "                if word.s.startswith(''.join([a if not isinstance(a, graphExample) else a.g for a in newSpell])):\n",
    "                    currentSpell.append(s)\n",
    "                    break\n",
    "            else:\n",
    "                newSpell.insert(0, s.g)\n",
    "                if word.s.endswith(''.join([a if not isinstance(a, graphExample) else a.g for a in newSpell])):\n",
    "                    currentSpell.insert(0, s)\n",
    "                    break                \n",
    "        if len(currentSpell) == oldLen:\n",
    "            break\n",
    "    return currentSpell\n",
    "\n",
    "def spell4(word, spellings, exLen=4, debug=False):\n",
    "    word.s = word.s.lower()\n",
    "    if not word.s.isalnum():\n",
    "        if debug:\n",
    "            print(\"bad characters\", word.s)\n",
    "        return False\n",
    "    if debug:\n",
    "        print(word)\n",
    "    phones = word.p.split()\n",
    "    if len(word.s) < len(phones):\n",
    "        if debug:\n",
    "            print(\"too long!\", word.s, phones)\n",
    "        return False\n",
    "    if not set(word.s) & set('aeiouy'):\n",
    "        if debug:\n",
    "            print(\"no vowels -> not a word!\", word.s, phones)\n",
    "        return False\n",
    "    if word.s[:-2] == 'le' and phones[:-2] == ['AH', 'L'] and word.s[-3] not in ['aeiou']:\n",
    "        phones.append(phones.pop[-2])\n",
    "        if debug:\n",
    "            print(\"special case: L\")\n",
    "    rphones = copy(phones)\n",
    "    rphones.reverse()\n",
    "    if debug:\n",
    "        print(\"phones\", phones, rphones)\n",
    "    frontSpell = sideSpell4(word, phones, spellings, 0)\n",
    "    frontStr = [a.g for a in frontSpell]\n",
    "    backSpell = sideSpell4(word, rphones, spellings, 1)\n",
    "    backStr = [a.g for a in backSpell]\n",
    "    if debug:\n",
    "        print(\"front & back\", frontSpell, backSpell)\n",
    "    if '' in frontSpell:\n",
    "        frontSpell.remove('')\n",
    "    if '' in backSpell:\n",
    "        backSpell.remove('')\n",
    "    if len(phones) > (len(frontSpell) + len(backSpell) + 1):\n",
    "        if debug:\n",
    "            print(\"failure to spell\")\n",
    "        return False\n",
    "    if frontSpell == backSpell and ''.join(frontStr) == word.s:\n",
    "        if debug:\n",
    "            print('yay!')\n",
    "            print(word, frontSpell, len(frontSpell))\n",
    "            print(backSpell, len(backSpell))\n",
    "            print(phones)\n",
    "        exPhone = choice(phones)\n",
    "        g = frontSpell[phones.index(exPhone)]\n",
    "        p = spellings[exPhone]\n",
    "        exGraph = p[p.index(g)]\n",
    "        if len(word.s) == exLen and not exGraph.set:\n",
    "            exGraph.setExample(word)\n",
    "        return True\n",
    "    missingG = graphExample(word.s.removeprefix(''.join(frontStr)).removesuffix(''.join(backStr)), isX=word.x)\n",
    "    #if not missingG.g:\n",
    "    #    missingG = backSpell[0]\n",
    "    if debug:\n",
    "        print(\"missing grapheme\", missingG)\n",
    "    if len(frontSpell + backSpell) > len(phones):\n",
    "            #print(word, frontSpell, len(frontSpell))\n",
    "            #print(backSpell, len(backSpell))\n",
    "            #print(phones)\n",
    "            if debug:\n",
    "                print(\"too long\")\n",
    "            del backSpell[0]\n",
    "    if len(frontSpell + backSpell) < len(phones):\n",
    "        try:\n",
    "            missingP = phones[len(frontSpell)]\n",
    "            if debug:\n",
    "                print(\"missing phoneme (clean)\", missingP)\n",
    "            if len(word.s) == exLen and not missingG.set:\n",
    "                missingG.setExample(word)        \n",
    "            spellings[missingP].append(missingG)    \n",
    "        except IndexError as e:\n",
    "            if debug:\n",
    "                print(word, frontSpell, len(frontSpell))\n",
    "                print(backSpell, len(backSpell))\n",
    "                print(phones)\n",
    "            raise e\n",
    "    else:\n",
    "        missingP = phones[len(frontSpell) - 1]\n",
    "        if debug:\n",
    "            print(\"missing phoneme (overlap)\", missingP)\n",
    "        try:\n",
    "            newG = graphExample(''.join((frontStr[-1], missingG.g) if frontStr else (missingG.g, backStr[0])), isX = missingG.g.count('x') or (frontStr[-1].count('x') if frontStr else backStr[0].count('x')))\n",
    "            if len(word.s) == exLen and not newG.set:\n",
    "                newG.setExample(word)  \n",
    "            spellings[missingP].append(newG)\n",
    "            if debug:\n",
    "                print(newG)\n",
    "        except IndexError as e:\n",
    "            if debug:\n",
    "                print(word, frontSpell, len(frontSpell))\n",
    "                print(backSpell, len(backSpell))\n",
    "                print(phones)\n",
    "                print(missingP)\n",
    "            raise e\n",
    "\n",
    "def learn3(spellings, words, exLen=4, debug=False):\n",
    "    newSpells = {s: copy(spellings[s]) for s in spellings}\n",
    "    for word in words:\n",
    "        spell3(word, newSpells, exLen=exLen, debug=debug)\n",
    "        if debug:\n",
    "            print(word, word.p)\n",
    "        #break\n",
    "    return newSpells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "467c2f53-766f-4882-b45b-2c96da099fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(aDict):\n",
    "    for key in aDict:\n",
    "        while '' in aDict[key]:\n",
    "            aDict[key].remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85ceca3f-0dca-4953-afb4-14101965c965",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "baseSpellings = {\n",
    "    'AA': ['o'],\n",
    "    'AE': ['a'],\n",
    "    'AH': ['u', 'o'],\n",
    "    'AO': ['o'],\n",
    "    'AW': ['ou'],\n",
    "    'AX': ['a'],\n",
    "    'AXR': ['er'],\n",
    "    'AY': ['i'],\n",
    "    'EH': ['e'],\n",
    "    'ER': ['ir'],\n",
    "    'EY': ['ai'],\n",
    "    'IH': ['i'],\n",
    "    'IX': ['e'],\n",
    "    'IY': ['ea'],\n",
    "    'OW': ['oa'],\n",
    "    'OY': ['oy'],\n",
    "    'UH': ['oo'],\n",
    "    'UW': ['oo'],\n",
    "    'UX': ['u'],\n",
    "    'B': ['b'],\n",
    "    'CH': ['ch'],\n",
    "    'D': ['d'],\n",
    "    'DX': ['tt'],\n",
    "    'EL': ['le'],\n",
    "    'EM': ['m'],\n",
    "    'EN': ['on'],\n",
    "    'F': ['f'],\n",
    "    'G': ['g'],\n",
    "    'H': ['h'],\n",
    "    'HH': ['h'],\n",
    "    'JH': ['j'],\n",
    "    'K': ['k'],\n",
    "    'L': ['l'],\n",
    "    'M': ['m'],\n",
    "    'N': ['n'],\n",
    "    'NX': ['ng'],\n",
    "    'NG': ['ng'],\n",
    "    'P': ['p'],\n",
    "    'Q': ['-'],\n",
    "    'R': ['r'],\n",
    "    'S': ['s'],\n",
    "    'SH': ['sh'],\n",
    "    'T': ['t'],\n",
    "    'TH': ['th'],\n",
    "    'V': ['v'],\n",
    "    'W': ['w'],\n",
    "    'WH': ['wh'],\n",
    "    'Y': ['y'],\n",
    "    'Z': ['z'],\n",
    "    'ZH': ['s']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28d6acb6-93f4-48cd-aeee-591cdb94fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class graphExample:\n",
    "    def __init__(self, grapheme, isX=False):\n",
    "        self.g = grapheme\n",
    "        self.set = False\n",
    "        self.isx = isX\n",
    "        self.x = 'x' if isX else None\n",
    "\n",
    "    def __str__(self):\n",
    "        try:\n",
    "            return f\"'{self.g if not self.isx else self.x}' in '{self.w}'\"\n",
    "        except AttributeError as e:\n",
    "            return self.g if not self.isx else self.x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, str):\n",
    "            return self.g == other\n",
    "        elif isinstance(other, graphExample):\n",
    "            return self.g == other.g\n",
    "        return False\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.g.__hash__() if not self.isx else self.x.__hash__()\n",
    "\n",
    "    def setExample(self, ex):\n",
    "        self.w = ex\n",
    "        self.set = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22761e16-2fb5-47b3-a327-64a26ff52604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initSpellings(plain):\n",
    "    ans = {p: [graphExample(a, isX=bool(a.count('x'))) for a in plain[p]] for p in plain}\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08d87fba-44ea-4934-9b28-1d5c57f17118",
   "metadata": {},
   "outputs": [],
   "source": [
    "coolSpellings = initSpellings(baseSpellings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4656dc05-2525-4e38-beaa-8c3d6c958f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA': [o],\n",
       " 'AE': [a],\n",
       " 'AH': [u, o],\n",
       " 'AO': [o],\n",
       " 'AW': [ou],\n",
       " 'AX': [a],\n",
       " 'AXR': [er],\n",
       " 'AY': [i],\n",
       " 'EH': [e],\n",
       " 'ER': [ir],\n",
       " 'EY': [ai],\n",
       " 'IH': [i],\n",
       " 'IX': [e],\n",
       " 'IY': [ea],\n",
       " 'OW': [oa],\n",
       " 'OY': [oy],\n",
       " 'UH': [oo],\n",
       " 'UW': [oo],\n",
       " 'UX': [u],\n",
       " 'B': [b],\n",
       " 'CH': [ch],\n",
       " 'D': [d],\n",
       " 'DX': [tt],\n",
       " 'EL': [le],\n",
       " 'EM': [m],\n",
       " 'EN': [on],\n",
       " 'F': [f],\n",
       " 'G': [g],\n",
       " 'H': [h],\n",
       " 'HH': [h],\n",
       " 'JH': [j],\n",
       " 'K': [k],\n",
       " 'L': [l],\n",
       " 'M': [m],\n",
       " 'N': [n],\n",
       " 'NX': [ng],\n",
       " 'NG': [ng],\n",
       " 'P': [p],\n",
       " 'Q': [-],\n",
       " 'R': [r],\n",
       " 'S': [s],\n",
       " 'SH': [sh],\n",
       " 'T': [t],\n",
       " 'TH': [th],\n",
       " 'V': [v],\n",
       " 'W': [w],\n",
       " 'WH': [wh],\n",
       " 'Y': [y],\n",
       " 'Z': [z],\n",
       " 'ZH': [s]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coolSpellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a8409dd-dc6c-4dae-942e-afd78ec0af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGLen(word):\n",
    "    pNum = len(word.p.split())\n",
    "    lNum = len(word.s)\n",
    "    minG = (lNum / pNum)\n",
    "    if minG > 4:\n",
    "        raise ValueError(\"too many letters\")\n",
    "    if minG < 1:\n",
    "        raise ValueError(\"too many phonemes\")\n",
    "    minG = int(minG)\n",
    "    maxG = min(lNum - pNum + 1, 4)\n",
    "    return (maxG, minG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bba9343c-2e25-490f-a1e5-30db3854a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atomize(word):\n",
    "    maxGraph, minGraph = getGLen(word)\n",
    "    lIndex = 0\n",
    "    potential = []\n",
    "    while lIndex < len(word.s):\n",
    "        for i in range(minGraph, maxGraph + 1):\n",
    "            atom = \"*\" * lIndex\n",
    "            atom += word.s[lIndex:lIndex + i]\n",
    "            atom += \"*\" * (len(word.s) - len(atom))\n",
    "            if atom not in potential:\n",
    "                potential.append(atom)\n",
    "        lIndex += 1\n",
    "    return potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7e73364-80fd-4aec-acb5-979d7525d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from math import ceil\n",
    "\n",
    "def match_phones2(word):\n",
    "    graphs = atomize(word)\n",
    "    phones = word.p.split()\n",
    "    #print(phones)\n",
    "    matches = {}\n",
    "    grange = range(len(graphs))\n",
    "    for p in phones:\n",
    "        matches[p] = []\n",
    "    for gInd in grange:\n",
    "        g = graphs[gInd]\n",
    "        if g.lstrip('*') == g:\n",
    "            matches[phones[0]].append(g)\n",
    "        elif g.rstrip('*') == g:\n",
    "            matches[phones[len(phones) - 1]].append(g)\n",
    "        else:\n",
    "            a = re.split('\\w', g)\n",
    "            endGaps = len(a[len(a) - 1])\n",
    "            absMin = ceil(len(a[0]) / getGLen(word)[0])\n",
    "            endPhones = len(phones[absMin + 1:])\n",
    "            pmin = absMin + (endPhones - endGaps if endGaps < endPhones else 0)\n",
    "            #pmax = max(len(a[0]) - ceil(endGaps / getGLen(word)[0]), 1)\n",
    "            absMax = ceil(endGaps / getGLen(word)[0])\n",
    "            pmax = min(len(phones) - 2, len(a[0]))\n",
    "            #pmax = min(len(a[0]), len(phones))\n",
    "            #print(g, pmin, pmax)\n",
    "            for p1 in phones[pmin: pmax + 1]:\n",
    "                matches[p1].append(g)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7073f323-9d07-421a-8469-43157a03e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_spaces(word, reverse=False):\n",
    "    letters = list(word)\n",
    "    count = 0\n",
    "    #print(word)\n",
    "    #print(letters)\n",
    "    if reverse:\n",
    "        while letters.pop() == '*':\n",
    "            count += 1\n",
    "    else:\n",
    "        while letters.pop(0) == '*':\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def count_letters(word):\n",
    "    letters = list(word)\n",
    "    count = 0\n",
    "    while len(letters) != 0 and letters.pop(0) != '*':\n",
    "        count += 1\n",
    "    return count\n",
    "    \n",
    "def stitch(matches):\n",
    "    stitched = matches.pop(0)\n",
    "    mapping = [0] * (len(stitched) - count_spaces(stitched, reverse=True))\n",
    "    num = 1\n",
    "    for grapheme in matches:\n",
    "        start = count_spaces(grapheme)\n",
    "        end = count_spaces(grapheme, reverse=True)\n",
    "        if start != len(stitched.strip('*')):\n",
    "            raise ValueError('bad match')\n",
    "        stitched = stitched.strip('*') + grapheme.lstrip('*')\n",
    "        newLetterNum = count_letters(grapheme.lstrip('*'))\n",
    "        mapping += [num] * newLetterNum\n",
    "        num += 1\n",
    "    return stitched, mapping\n",
    "\n",
    "def fancyPrint(stitchObj):\n",
    "    print(stitchObj[0])\n",
    "    print(''.join([str(i) for i in stitchObj[1]]))\n",
    "\n",
    "def recursionPractice(listOfLists):\n",
    "    return stitch(['something', recursionPractice('something else')])\n",
    "\n",
    "def combinatory(length, bases):\n",
    "    combs = []\n",
    "    \n",
    "\n",
    "def getIndices(matchDict):\n",
    "    lengths = [len(matchDict[i]) for i in matchDict]\n",
    "    indices = []\n",
    "    pass\n",
    "\n",
    "def stitchAll(matchDict, phoneInds, graphInds):\n",
    "    phones = matchDict.keys()\n",
    "    for graph in matchDict[phone]:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd728b59-3a15-4b31-8c12-8fbbb58cf740",
   "metadata": {},
   "source": [
    "11/12\n",
    "\n",
    "Copied over everything I remember being important. Now it's time to start my newest attempt: combining both major attempts so far.\n",
    "\n",
    "I intend to write functions that provide every possible spelling of a word, and every potential grapheme-to-phoneme mapping. Once I can visualize that, hopefully I will have a better idea of what to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "978e60a3-225a-416a-ad2c-9a34342c3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class customBase(list):\n",
    "#    def __init__(self, baseList):\n",
    "#       self.zero = [0] * len(baseList)\n",
    "#        self.current = [0] * len(baseList)\n",
    "#        self.max = baseList\n",
    "#        super().__init__(self, i for i in baseList)\n",
    "\n",
    "\n",
    "    \n",
    "#    def __iadd__(self, other):\n",
    "#        if isinstance(other, (int, float)):\n",
    "#            \n",
    "#        else:\n",
    "#            return super().__iadd__(self, other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db0871f3-785e-446a-a101-f1562f5168aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import prod\n",
    "\n",
    "class customBase():\n",
    "    def __init__(self, baseInt):\n",
    "        self.baseRaw = baseInt\n",
    "        baseList = list(str(baseInt))\n",
    "        self.bases = [int(i) for i in baseList]\n",
    "        self.baseMax = prod(self.bases)\n",
    "        self.baseReprs = []\n",
    "        k = range(len(self.bases))\n",
    "        for i in k:\n",
    "            self.baseReprs.append(prod(self.bases[:i:-1]))\n",
    "        self.brc = reversed(self.baseReprs)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"base {self.bases}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "class customBaseInt():\n",
    "    def __init__(self, customBase, n):\n",
    "        if n > customBase.baseMax:\n",
    "            raise ValueError(f\"{n} larger than custom base's maximum value of {customBase.baseMax}\")\n",
    "        self.dec = n\n",
    "        self.base = customBase\n",
    "        self.nBasedList = []\n",
    "        for b in self.base.baseReprs:\n",
    "            a, n = divmod(n, b)\n",
    "            self.nBasedList.append(a)\n",
    "        self.nBased = int(''.join([str(i) for i in self.nBasedList]))\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.nBased\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.nBased} in base {self.base.bases}, {self.dec} in decimal\"\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "        if isinstance(other, (int, float)):\n",
    "            return customBaseInt(self.base, self.dec + other)\n",
    "        else:\n",
    "            raise TypeError(f\"assignment addition not supported between objects of type {type(self)} and {type(other)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52c4b643-42ce-4cab-9e3d-ba9c6fc9fb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "611 in base [2, 7, 3, 4], 77 in decimal"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newBase = customBase(2734)\n",
    "newInt = customBaseInt(newBase, 77)\n",
    "newInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "376d30b8-120b-402c-8910-3739f3a58ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612 in base [2, 7, 3, 4], 78 in decimal"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newInt += 1\n",
    "newInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4db8f46-4ecf-4eaf-b990-d2be4bddea21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import prod\n",
    "\n",
    "a = [2,3,4,5,6]\n",
    "prod(a[:0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "923b0fee-a55f-469d-a5e6-ead50b66e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import prod\n",
    "\n",
    "def multiIndex(l, indices):\n",
    "    ans = []\n",
    "    for i in indices:\n",
    "        ans.append(l[i])\n",
    "    return ans\n",
    "\n",
    "def getAllSpells(word, spellings):\n",
    "    allspells = []\n",
    "    phones = word.p.split()\n",
    "    phoneLens = [len(spellings[p]) for p in phones]\n",
    "    phoneNumBase = customBase(int(''.join([str(i) for i in phoneLens])))\n",
    "    phoneNum = customBaseInt(phoneNumBase, 0)\n",
    "    while True:\n",
    "        try:\n",
    "            tempDict = {}\n",
    "            for i in range(len(phones)):\n",
    "                tempDict[phones[i]] = phoneNum.nBasedList[i]\n",
    "                \n",
    "            allspells.append([spellings[phones[i]] for i in phoneNum.nBasedList])\n",
    "        except ValueError:\n",
    "            return allSpells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bdd184-ac43-437f-b8a2-09e1601e1e74",
   "metadata": {},
   "source": [
    "11/14\n",
    "\n",
    "I don't exactly remember what the above ^^^ cell was about, so I'm going to try again. I have a way to generate numbers how I want, I just need to iterate through each possible spelling using those numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b080a18b-8eb6-4139-8209-a02b6ec93a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpell(graphNums, phoneDict):\n",
    "    \"\"\" \n",
    "        Arguments:\n",
    "            graphNums (list of tuples): a list of two-tuples. the first item of each tuple is the phoneme, and the second is an index number.\n",
    "            phoneDict (dict): the dictionary of phonemes and graphemes to index.\n",
    "    \"\"\"\n",
    "    ans = []\n",
    "    for phone, gNum in graphNums:\n",
    "        ans.append(phoneDict[phone][gNum])\n",
    "    return ans\n",
    "\n",
    "def getAllSpells(word, phoneDict):\n",
    "    ans = []\n",
    "    phones = word.p.split()\n",
    "    #print(phones)\n",
    "    phoneLens = [len(phoneDict[p]) for p in phones]\n",
    "    #print(phoneLens)\n",
    "    phoneNumBase = customBase(int(''.join([str(i) for i in phoneLens])))\n",
    "    for i in range(phoneNumBase.baseMax):\n",
    "        inum = customBaseInt(phoneNumBase, i)\n",
    "        zippedPhones = zip(phones, inum.nBasedList)\n",
    "        #print(zippedPhones)\n",
    "        ans.append((inum.nBasedList, getSpell(zippedPhones, phoneDict)))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "613a91c9-f01d-4cea-ade1-2b44d533a123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newBase = customBase(1234)\n",
    "customBaseInt(newBase, 0).nBasedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "542129a8-e525-4ee6-81da-b23b16053641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1da5879f-1271-4f9e-b8d5-af75595ac2af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learnedSpells = learn3(coolSpellings, twoLetter, exLen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a342700-a7f3-48cc-be15-37b069df80d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA': ['o' in 'og', 'ah' in 'ah', 'a' in 'ar'],\n",
       " 'AE': ['a' in 'ad'],\n",
       " 'AH': ['u' in 'du', 'o' in 'of', 'e' in 'em', 'a' in 'an', 'uh' in 'uh'],\n",
       " 'AO': ['o' in 'om', 'aw' in 'aw'],\n",
       " 'AW': [ou, 'ow' in 'ow'],\n",
       " 'AX': [a],\n",
       " 'AXR': [er],\n",
       " 'AY': ['i' in 'fi', 'ai' in 'ai', 'ay' in 'ay', 'y' in 'by'],\n",
       " 'EH': ['e' in 'ed', 'a' in 'as', 'eh' in 'eh'],\n",
       " 'ER': [ir, 'er' in 'er', 'or' in 'or', 'ur' in 'ur'],\n",
       " 'EY': [ai,\n",
       "  'aa' in 'aa',\n",
       "  'ae' in 'ae',\n",
       "  'ai' in 'ai',\n",
       "  'ay' in 'ay',\n",
       "  'e' in 'de',\n",
       "  'y' in 'wy'],\n",
       " 'IH': ['i' in 'ib', 'o' in 'to'],\n",
       " 'IX': [e],\n",
       " 'IY': [ea, 'e' in 'be', 'i' in 'di', 'y' in 'uy'],\n",
       " 'OW': [oa, 'au' in 'au', 'o' in 'bo', 'oh' in 'oh', 'ow' in 'ow'],\n",
       " 'OY': ['oy' in 'oy', 'oi' in 'oi'],\n",
       " 'UH': [oo],\n",
       " 'UW': [oo, 'o' in 'do', 'u' in 'du', 'o' in 'ou'],\n",
       " 'UX': [u],\n",
       " 'B': ['b' in 'ab'],\n",
       " 'CH': [ch],\n",
       " 'D': ['d' in 'di'],\n",
       " 'DX': [tt],\n",
       " 'EL': [le],\n",
       " 'EM': [m],\n",
       " 'EN': [on],\n",
       " 'F': ['f' in 'fe'],\n",
       " 'G': ['g' in 'go'],\n",
       " 'H': [h],\n",
       " 'HH': ['h' in 'ha'],\n",
       " 'JH': ['j' in 'ji'],\n",
       " 'K': ['k' in 'ke', 'c' in 'ca', 'q' in 'qi'],\n",
       " 'L': ['l' in 'al'],\n",
       " 'M': ['m' in 'em'],\n",
       " 'N': ['n' in 'en'],\n",
       " 'NX': [ng],\n",
       " 'NG': [ng],\n",
       " 'P': ['p' in 'op'],\n",
       " 'Q': [-],\n",
       " 'R': ['r' in 'ra'],\n",
       " 'S': ['s' in 'es', 'c' in 'cy'],\n",
       " 'SH': [sh, 'x' in 'xi'],\n",
       " 'T': ['t' in 'it'],\n",
       " 'TH': [th],\n",
       " 'V': ['v' in 've', 'f' in 'of'],\n",
       " 'W': ['w' in 'wu'],\n",
       " 'WH': [wh],\n",
       " 'Y': ['y' in 'ye', 'j' in 'ja'],\n",
       " 'Z': ['z' in 'oz', 's' in 'as'],\n",
       " 'ZH': [s]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnedSpells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "734f7f77-cdc2-470b-a73e-dc4a90bef215",
   "metadata": {},
   "outputs": [],
   "source": [
    "breath = wordObjs2['BREATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28391618-aec3-4066-91bf-c7a0039493e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allSpells = getAllSpells(breath, learnedSpells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9d89f7e-63c8-431c-980d-5b01f3af79a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0, 0, 0, 0], ['b' in 'ab', 'r' in 'ra', 'e' in 'ed', th]),\n",
       " ([0, 0, 1, 0], ['b' in 'ab', 'r' in 'ra', 'a' in 'as', th]),\n",
       " ([0, 0, 2, 0], ['b' in 'ab', 'r' in 'ra', 'eh' in 'eh', th])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allSpells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46a80c84-b137-430d-b113-ffd8bbb2af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettyPrintAllSpells(allSpellTuples):\n",
    "    for p, n in allSpellTuples:\n",
    "        print(p)\n",
    "        print(n)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0501a00-cf77-42bb-a26a-0e8ad50e1e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0]\n",
      "['b' in 'ab', 'r' in 'ra', 'e' in 'ed', th]\n",
      "\n",
      "\n",
      "[0, 0, 1, 0]\n",
      "['b' in 'ab', 'r' in 'ra', 'a' in 'as', th]\n",
      "\n",
      "\n",
      "[0, 0, 2, 0]\n",
      "['b' in 'ab', 'r' in 'ra', 'eh' in 'eh', th]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prettyPrintAllSpells(allSpells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d41af-53e5-4935-9eb3-f568429534d7",
   "metadata": {},
   "source": [
    "nice!! it seems to work. now to mess with the match_phones stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d357b3f6-4900-42ad-a857-e405bf39c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "breathMatched = match_phones2(breath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03a1efad-14f4-42ce-95c5-287937096b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': ['b*****', 'br****', 'bre***'],\n",
       " 'R': ['*r****', '*re***', '*rea**', '**e***', '**ea**', '***a**'],\n",
       " 'EH': ['**e***', '**ea**', '**eat*', '***a**', '***at*', '****t*'],\n",
       " 'TH': ['***ath', '****th', '*****h']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breathMatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f6733b9-2219-4bca-8968-81295eb8d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitchAll(matchDict):\n",
    "    ans = []\n",
    "    phoneLens = [len(matchDict[i]) for i in matchDict]\n",
    "    matchBase = customBase(int(''.join([str(i) for i in phoneLens])))\n",
    "    for i in range(matchBase.baseMax):\n",
    "        inum = customBaseInt(matchBase, i)\n",
    "        toStitch = []\n",
    "        for j, k in zip(matchDict.values(), inum.nBasedList):\n",
    "            #print(j, k)\n",
    "            toStitch.append(j[k])\n",
    "        try:\n",
    "            ans.append((inum.nBasedList, stitch(toStitch)))\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff6ba87b-d041-4065-b5ec-44021ccf65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "breathStitched = stitchAll(breathMatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f692610b-200f-43b6-b636-2814da37c5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0, 0, 0, 0], ('breath', [0, 1, 2, 3, 3, 3])),\n",
       " ([0, 0, 1, 1], ('breath', [0, 1, 2, 2, 3, 3])),\n",
       " ([0, 0, 2, 2], ('breath', [0, 1, 2, 2, 2, 3])),\n",
       " ([0, 1, 3, 1], ('breath', [0, 1, 1, 2, 3, 3])),\n",
       " ([0, 1, 4, 2], ('breath', [0, 1, 1, 2, 2, 3])),\n",
       " ([0, 2, 5, 2], ('breath', [0, 1, 1, 1, 2, 3])),\n",
       " ([1, 3, 3, 1], ('breath', [0, 0, 1, 2, 3, 3])),\n",
       " ([1, 3, 4, 2], ('breath', [0, 0, 1, 2, 2, 3])),\n",
       " ([1, 4, 5, 2], ('breath', [0, 0, 1, 1, 2, 3])),\n",
       " ([2, 5, 5, 2], ('breath', [0, 0, 0, 1, 2, 3]))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breathStitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71ef3448-9082-4643-92aa-fb306d7aece0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breath\n",
      "012333\n",
      "\n",
      "\n",
      "breath\n",
      "012233\n",
      "\n",
      "\n",
      "breath\n",
      "012223\n",
      "\n",
      "\n",
      "breath\n",
      "011233\n",
      "\n",
      "\n",
      "breath\n",
      "011223\n",
      "\n",
      "\n",
      "breath\n",
      "011123\n",
      "\n",
      "\n",
      "breath\n",
      "001233\n",
      "\n",
      "\n",
      "breath\n",
      "001223\n",
      "\n",
      "\n",
      "breath\n",
      "001123\n",
      "\n",
      "\n",
      "breath\n",
      "000123\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in breathStitched:\n",
    "    fancyPrint(b[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190e5f7-194e-4e3b-879b-848c423d82fd",
   "metadata": {},
   "source": [
    "beautiful. didn't take me long to get this working.\n",
    "\n",
    "now for the hard part. I need to figure out how to combine both techniques to ensure that my code only learns correct spellings.\n",
    "\n",
    "vvv copied from above, for easier viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1da9c6a-e06d-4ea8-864c-15ac5f8d93bd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## from time import sleep\n",
    "from copy import copy\n",
    "\n",
    "def sideSpell4(word, phones, spells, polarity):\n",
    "    currentSpell = []\n",
    "    for p in phones:\n",
    "        oldLen = len(currentSpell)\n",
    "        for s in spells[p]:\n",
    "            newSpell = copy(currentSpell)\n",
    "            if not polarity:\n",
    "                newSpell.append(s.g)\n",
    "                if word.s.startswith(''.join([a if not isinstance(a, graphExample) else a.g for a in newSpell])):\n",
    "                    currentSpell.append(s)\n",
    "                    break\n",
    "            else:\n",
    "                newSpell.insert(0, s.g)\n",
    "                if word.s.endswith(''.join([a if not isinstance(a, graphExample) else a.g for a in newSpell])):\n",
    "                    currentSpell.insert(0, s)\n",
    "                    break                \n",
    "        if len(currentSpell) == oldLen:\n",
    "            break\n",
    "    return currentSpell\n",
    "\n",
    "def spell4(word, spellings, exLen=4, debug=False):\n",
    "    word.s = word.s.lower()\n",
    "    if not word.s.isalnum():\n",
    "        if debug:\n",
    "            print(\"bad characters\", word.s)\n",
    "        return False\n",
    "    if debug:\n",
    "        print(word)\n",
    "    phones = word.p.split()\n",
    "    if len(word.s) < len(phones):\n",
    "        if debug:\n",
    "            print(\"too long!\", word.s, phones)\n",
    "        return False\n",
    "    if not set(word.s) & set('aeiouy'):\n",
    "        if debug:\n",
    "            print(\"no vowels -> not a word!\", word.s, phones)\n",
    "        return False\n",
    "    if word.s[:-2] == 'le' and phones[:-2] == ['AH', 'L'] and word.s[-3] not in ['aeiou']:\n",
    "        phones.append(phones.pop[-2])\n",
    "        if debug:\n",
    "            print(\"special case: L\")\n",
    "    rphones = copy(phones)\n",
    "    rphones.reverse()\n",
    "    if debug:\n",
    "        print(\"phones\", phones, rphones)\n",
    "    frontSpell = sideSpell4(word, phones, spellings, 0)\n",
    "    frontStr = [a.g for a in frontSpell]\n",
    "    backSpell = sideSpell4(word, rphones, spellings, 1)\n",
    "    backStr = [a.g for a in backSpell]\n",
    "    if debug:\n",
    "        print(\"front & back\", frontSpell, backSpell)\n",
    "    if '' in frontSpell:\n",
    "        frontSpell.remove('')\n",
    "    if '' in backSpell:\n",
    "        backSpell.remove('')\n",
    "    if len(phones) > (len(frontSpell) + len(backSpell) + 1):\n",
    "        if debug:\n",
    "            print(\"failure to spell\")\n",
    "        return False\n",
    "    if frontSpell == backSpell and ''.join(frontStr) == word.s:\n",
    "        if debug:\n",
    "            print('yay!')\n",
    "            print(word, frontSpell, len(frontSpell))\n",
    "            print(backSpell, len(backSpell))\n",
    "            print(phones)\n",
    "        exPhone = choice(phones)\n",
    "        g = frontSpell[phones.index(exPhone)]\n",
    "        p = spellings[exPhone]\n",
    "        exGraph = p[p.index(g)]\n",
    "        if len(word.s) == exLen and not exGraph.set:\n",
    "            exGraph.setExample(word)\n",
    "        return True\n",
    "    missingG = graphExample(word.s.removeprefix(''.join(frontStr)).removesuffix(''.join(backStr)), isX=word.x)\n",
    "    #if not missingG.g:\n",
    "    #    missingG = backSpell[0]\n",
    "    if debug:\n",
    "        print(\"missing grapheme\", missingG)\n",
    "    if len(frontSpell + backSpell) > len(phones):\n",
    "            #print(word, frontSpell, len(frontSpell))\n",
    "            #print(backSpell, len(backSpell))\n",
    "            #print(phones)\n",
    "            if debug:\n",
    "                print(\"too long\")\n",
    "            del backSpell[0]\n",
    "    if len(frontSpell + backSpell) < len(phones):\n",
    "        try:\n",
    "            missingP = phones[len(frontSpell)]\n",
    "            if debug:\n",
    "                print(\"missing phoneme (clean)\", missingP)\n",
    "            if len(word.s) == exLen and not missingG.set:\n",
    "                missingG.setExample(word)        \n",
    "            spellings[missingP].append(missingG)    \n",
    "        except IndexError as e:\n",
    "            if debug:\n",
    "                print(word, frontSpell, len(frontSpell))\n",
    "                print(backSpell, len(backSpell))\n",
    "                print(phones)\n",
    "            raise e\n",
    "    else:\n",
    "        missingP = phones[len(frontSpell) - 1]\n",
    "        if debug:\n",
    "            print(\"missing phoneme (overlap)\", missingP)\n",
    "        try:\n",
    "            newG = graphExample(''.join((frontStr[-1], missingG.g) if frontStr else (missingG.g, backStr[0])), isX = missingG.g.count('x') or (frontStr[-1].count('x') if frontStr else backStr[0].count('x')))\n",
    "            if len(word.s) == exLen and not newG.set:\n",
    "                newG.setExample(word)  \n",
    "            spellings[missingP].append(newG)\n",
    "            if debug:\n",
    "                print(newG)\n",
    "        except IndexError as e:\n",
    "            if debug:\n",
    "                print(word, frontSpell, len(frontSpell))\n",
    "                print(backSpell, len(backSpell))\n",
    "                print(phones)\n",
    "                print(missingP)\n",
    "            raise e\n",
    "\n",
    "def learn3(spellings, words, exLen=4, debug=False):\n",
    "    newSpells = {s: copy(spellings[s]) for s in spellings}\n",
    "    for word in words:\n",
    "        spell3(word, newSpells, exLen=exLen, debug=debug)\n",
    "        if debug:\n",
    "            print(word, word.p)\n",
    "        #break\n",
    "    return newSpells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d44d5a38-6c57-4b07-a3bf-f38ed1fb248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newSpell(word, phoneDict, exLen=4):\n",
    "    phones = word.p.split()\n",
    "    allGraphs = getAllSpells(word, phoneDict)\n",
    "    matches = match_phones2(word)\n",
    "    allStitches = stitchAll(matches)\n",
    "    print(allStitches)\n",
    "    print(allGraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217fbc2-5f23-4ced-b423-34c6f65dab9d",
   "metadata": {},
   "source": [
    "12/3\n",
    "\n",
    "Experimentation & Refamiliarization (it's been a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1685ba5-2bbb-44db-9f98-94c0a1d51a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([0, 0, 0, 0], ('breath', [0, 1, 2, 3, 3, 3])), ([0, 0, 1, 1], ('breath', [0, 1, 2, 2, 3, 3])), ([0, 0, 2, 2], ('breath', [0, 1, 2, 2, 2, 3])), ([0, 1, 3, 1], ('breath', [0, 1, 1, 2, 3, 3])), ([0, 1, 4, 2], ('breath', [0, 1, 1, 2, 2, 3])), ([0, 2, 5, 2], ('breath', [0, 1, 1, 1, 2, 3])), ([1, 3, 3, 1], ('breath', [0, 0, 1, 2, 3, 3])), ([1, 3, 4, 2], ('breath', [0, 0, 1, 2, 2, 3])), ([1, 4, 5, 2], ('breath', [0, 0, 1, 1, 2, 3])), ([2, 5, 5, 2], ('breath', [0, 0, 0, 1, 2, 3]))]\n",
      "[([0, 0, 0, 0], ['b' in 'ab', 'r' in 'ra', 'e' in 'ed', th])]\n"
     ]
    }
   ],
   "source": [
    "newSpell(wordObjs2['BREATH'], coolSpellings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c99a1977-f1bc-483f-8323-9af194cce474",
   "metadata": {},
   "outputs": [],
   "source": [
    "angry = wordObjs2['ANGRY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ab2b67b-fc29-466d-b479-b6be3deb34ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AE NG G R IY'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angry.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78270cea-6f03-4ba1-910e-2d06cb545923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(angry.p.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9c598ad-a2d0-48eb-89d6-f9c4c988362b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'angry'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angry.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ddd8103-837b-4a68-b38c-fcaf5e8a7dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(angry.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e024025d-ee68-4d52-ad91-f2078d12f563",
   "metadata": {},
   "outputs": [],
   "source": [
    "easyWords = [wordObjs2[i] for i in wordObjs2 if len(wordObjs2[i].p.split()) == len(wordObjs2[i].s) and \"'\" not in wordObjs2[i].s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "621e29e0-593d-4826-ba92-580d743a9849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34517"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(easyWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "797b2634-faa9-4aeb-a92e-73f2082c71d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134373"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordObjs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b27784d4-f67b-4d4b-9224-2675ed5e2371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hobart', 'HH OW B AA R T'), ('brunken', 'B R AH NG K AH N'), ('seidl', 'S AY D AH L'), ('betzold', 'B EH T Z OW L D'), ('deblasio', 'D IH B L AA S IY OW'), ('park', 'P AA R K'), ('danahy', 'D AE N AH HH IY'), ('nagata', 'N AA G AA T AH'), ('materialistic', 'M AH T IH R IY AH L IH S T IH K'), ('relondo', 'R IH L AO N D OW'), ('lukens', 'L UW K AH N Z'), ('resembled', 'R IY Z EH M B AH L D'), ('siksty', 'S IH K S T IY'), ('davida', 'D AA V IY D AH'), ('kirov', 'K IH R AA V')]\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "print([(i.s, i.p) for i in sample(easyWords, 15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47105550-e541-407a-9bdf-c4515428defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleTest = copy(coolSpellings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7083915c-1f4a-478e-a983-cf703548e110",
   "metadata": {},
   "source": [
    "I thought that I could start teaching my dictionary with the assumption that words with equivalent amounts of sounds and letters meant it provided "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b99a8ac-0394-446b-a966-a3d011412b48",
   "metadata": {},
   "source": [
    "given a word, find another word that differs by one phoneme. the letters that change between words represent the varied phoneme.\n",
    "\n",
    "<i>can it really be that simple?</i>\n",
    "\n",
    "I don't think so. 'fair' and 'care' differ by one sound, but sounds shared between them are spelled differently as well.\n",
    "\n",
    "could I use phoneme sequence analysis to determine which changed letters belong to the variable sound?\n",
    ">Probably not. PSA assumed no silent letters, which is just not true here.\n",
    "\n",
    "what about consonant-vowel sequence analysis? if non-loaned English words have the repeating pattern C^m V C^n, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12a63328-7b80-41b5-9fc9-2fbf9fee7c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneOff(word, wordDict, testWord = None):\n",
    "    ans = []\n",
    "    if testWord != None:\n",
    "        wordDict = {0: testWord}\n",
    "    for i in wordDict:\n",
    "        w = wordDict[i]\n",
    "        ind = 0\n",
    "        mismatchCount = 0\n",
    "        if len(w.p.split()) == len(word.p.split()): \n",
    "            #print(w)\n",
    "            for sound in w.p.split():\n",
    "                #print(sound, word.p.split()[ind])\n",
    "                if sound != word.p.split()[ind]:\n",
    "                    #print('not a match')\n",
    "                    mismatchCount += 1\n",
    "                ind += 1\n",
    "            if mismatchCount == 1:\n",
    "                ans.append(w)\n",
    "            #break\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38e7b20f-d7cb-4713-871d-0fa7c878cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newBreath = wordObjs2['BREATH']\n",
    "newBreath1 = getOneOff(newBreath, wordObjs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b0bcf35-4a69-4ed7-958f-58ae4039d015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newBreath1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e22ca00c-094d-4089-8f9a-5cb26a87e7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'rith,\n",
       " bread,\n",
       " breck,\n",
       " bred,\n",
       " brehm,\n",
       " brekke,\n",
       " brem,\n",
       " bren,\n",
       " brenn,\n",
       " bress,\n",
       " bresse,\n",
       " bret,\n",
       " brett,\n",
       " broth,\n",
       " creath,\n",
       " greth]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newBreath1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c8dcf32-96d3-4341-b5f1-2466c74a08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOffInd(word, other):\n",
    "    ind = 0\n",
    "    for sound in word.p.split():\n",
    "        if other.p.split()[ind] != sound:\n",
    "            return ind\n",
    "        ind += 1\n",
    "\n",
    "def organizeOneOffs(word, offs):\n",
    "    ans = {i: [] for i in range(len(word.p.split()))}\n",
    "    for o in offs:\n",
    "        ans[getOffInd(word, o)].append(o)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9cee3a50-8cf6-4948-9a88-76758ff9e42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [creath, greth],\n",
       " 1: [],\n",
       " 2: [b'rith, broth],\n",
       " 3: [bread,\n",
       "  breck,\n",
       "  bred,\n",
       "  brehm,\n",
       "  brekke,\n",
       "  brem,\n",
       "  bren,\n",
       "  brenn,\n",
       "  bress,\n",
       "  bresse,\n",
       "  bret,\n",
       "  brett]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organizeOneOffs(newBreath, newBreath1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef72cb0-3e03-4345-b42f-7cd88902e4b1",
   "metadata": {},
   "source": [
    "Given a word, I can find all words that differ by exactly one sound, and group them by the variable sound.\n",
    "\n",
    "Now, I need a way to 'subtract' two words, in order to find "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43ee99ef-ce3c-4f6a-baf7-25c858ab98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "anger = wordObjs2['ANGER']\n",
    "anger1 = getOneOff(anger, wordObjs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d3ce9929-c813-43d5-ba4f-61df84cb8d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anger1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "41ae14db-c7e9-4cd0-a72a-e11c88a963e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [enger, ingar, ungar, unger], 1: [apgar], 2: [anchor, anker], 3: []}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organizeOneOffs(anger, anger1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2057dc30-eb3e-46e2-9cac-ee3efb3e9a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AE NG G ER'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anger.p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9b5777-7e54-495f-960d-3e3e44f81794",
   "metadata": {},
   "source": [
    "NEW APPROACH: given some input like the dictionaries above, what should a smart program learn?\n",
    "\n",
    "aka: what patterns do I notice when I look at them?\n",
    "\n",
    "From the anger dict:\n",
    "\n",
    "1. \\[vowel\\] + 'ng' + junk => /vowel sound/ + /NG/ + /G/ + junk\n",
    "2. junk + 'ng' + vowel + 'r' => junk + /NG/ + /G/ + /ER/\n",
    "3. 'a' => /AE/\n",
    "\n",
    "From the breath dict:\n",
    "\n",
    "1. 'b' at beginning of word => /B/\n",
    "2. 'r' as second letter => /R/\n",
    "3. 'br' => /BR/\n",
    "4. junk + vowels + 'th' => junk + /vowel sound/ + /TH/\n",
    "5. /EH/ => 'ea' or 'e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bacebb10-86c5-4518-ad92-6d2d0b3d9ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B R EH TH'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newBreath.p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b6b488-e275-43ce-9f36-debbc64caa48",
   "metadata": {},
   "source": [
    "12/5\n",
    "\n",
    "So I realized that the above Markdown cell (along with some paper sketches) was essentially reinventing learning models, but manual. I don't like using models, as it's a black box that cannot be understood. Ideally, my program would know how to discover new patterns in some format, and use those to learn new spellings. It could work, but I'm not sure. So far, it seems very difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "878024be-84ab-464c-ba35-6d3c2023a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "creation = wordObjs2['CREATION']\n",
    "creation1 = getOneOff(creation, wordObjs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cfea96c7-093b-489f-80a6-2e87e1d8b460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'K R IY EY SH AH N'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creation.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "71f9b760-a1b4-4475-8cae-89941395e85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [], 1: [], 2: [croatian], 3: [], 4: [], 5: [], 6: []}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organizeOneOffs(creation, creation1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e0204ff-0b9e-48bd-a7cd-cb9b60b2cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "blinking = wordObjs2['BLINKING']\n",
    "blinking1 = getOneOff(blinking, wordObjs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c93620e6-3817-425f-8471-9644d8c2363f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B L IH NG K IH NG'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blinking.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be98a485-f91b-484f-a500-881a1cab3f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [plinking], 1: [], 2: [blanking], 3: [], 4: [], 5: [], 6: []}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organizeOneOffs(blinking, blinking1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "219dbfc3-8f17-48c4-be54-8279e45954af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSomeOffs(word, wordDict, offset:int, testWord = None):\n",
    "    ans = []\n",
    "    if testWord != None:\n",
    "        wordDict = {0: testWord}\n",
    "    for i in wordDict:\n",
    "        w = wordDict[i]\n",
    "        ind = 0\n",
    "        mismatchCount = 0\n",
    "        if len(w.p.split()) == len(word.p.split()): \n",
    "            #print(w)\n",
    "            for sound in w.p.split():\n",
    "                #print(sound, word.p.split()[ind])\n",
    "                if sound != word.p.split()[ind]:\n",
    "                    #print('not a match')\n",
    "                    mismatchCount += 1\n",
    "                ind += 1\n",
    "            if mismatchCount == offset:\n",
    "                ans.append(w)\n",
    "            #break\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b6bfc5c8-d6b5-42dd-8214-7f9009d34b3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "84681",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m getSomeOffs(wordObjs2[\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwordObjs2\u001b[49m\u001b[43m)\u001b[49m], wordObjs2, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/random.py:378\u001b[0m, in \u001b[0;36mRandom.choice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# raises IndexError if seq is empty\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mseq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_randbelow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 84681"
     ]
    }
   ],
   "source": [
    "getSomeOffs(wordObjs2[choice(wordObjs2)], wordObjs2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bc1abc7a-c801-45b6-a169-81eeda9cfd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(getSomeOffs(breath, wordObjs2, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
